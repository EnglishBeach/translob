{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a70cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from LobTransformer import TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1fc8934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f35474c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf797c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0cd39c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b-a).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "01beb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "a={}\n",
    "# download FI2010 dataset from \n",
    "# https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649\n",
    "FI2010_DIR = r'D:\\WORKS\\translob\\dataset\\BenchmarkDatasets'\n",
    "\n",
    "def gen_data(data, horizon):\n",
    "    x = data[:40, :].T  # 40 == 10 price + volume asks + 10 price + volume bids\n",
    "    # FIXME: delete .T\n",
    "    y = data[-5 + horizon, :].T  # 5\n",
    "    return x[:-1], (y[1:] - 1).astype(np.int32)  # shift y by 1\n",
    "\n",
    "\n",
    "def load_dataset(horizon):\n",
    "    global a\n",
    "    a.update({'start':datetime.now()})\n",
    "    \n",
    "    dec_data = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt'\n",
    "    )\n",
    "    a.update({'train':datetime.now()})\n",
    "    \n",
    "    dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "    dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "    \n",
    "    a.update({'train_eval':datetime.now()})\n",
    "    \n",
    "    dec_test1 = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_7.txt'\n",
    "    )\n",
    "    \n",
    "    a.update({'test1':datetime.now()})\n",
    "    \n",
    "    dec_test2 = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_8.txt'\n",
    "    )\n",
    "    \n",
    "    a.update({'test2':datetime.now()})\n",
    "    \n",
    "    dec_test3 = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "    )\n",
    "    a.update({'test3':datetime.now()})\n",
    "    \n",
    "    dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "    \n",
    "    a.update({'stack':datetime.now()})\n",
    "    \n",
    "    result = (\n",
    "        gen_data(dec_train,horizon), \n",
    "        gen_data(dec_val,horizon), \n",
    "        gen_data(dec_test, horizon)) #yapf: disable\n",
    "    \n",
    "    a.update({'result':datetime.now()})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6a83aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dif(a):\n",
    "    keys= list(a.keys())\n",
    "    result={ \n",
    "        keys[i]:(a[keys[i]]-a[keys[i-1]]).total_seconds()\n",
    "        for i in range(1,len(keys))\n",
    "    } #yapf:disable\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4c08681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_dataset(horizon=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "593ca673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 9.116525,\n",
       " 'train_eval': 0.0,\n",
       " 'test1': 1.962616,\n",
       " 'test2': 1.857686,\n",
       " 'test3': 1.187247,\n",
       " 'stack': 0.066204,\n",
       " 'result': 0.001999}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dif(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef29505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of fi2020 module from start\n",
    "# a = np.array([\n",
    "#     2615, 353, 2618, 200, 2619, 164, 2620, 532, 2621, 151, 2623, 837, 2625,\n",
    "#     150, 2626, 787, 2629, 146, 2633, 311, 2606, 326, 2604, 682, 2602, 786,\n",
    "#     2600, 893, 2599, 159, 2595, 100, 2593, 143, 2591, 134, 2588, 123, 2579, 128\n",
    "# ])\n",
    "# x_train[0]*a+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef9034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PositionalEncodingLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, *args, **kwargs):\n",
    "        steps, d_model = x.get_shape()[-2:]\n",
    "        global A \n",
    "        A= x,steps,d_model\n",
    "        ps = np.zeros([steps, 1], dtype=K.floatx())\n",
    "        for step in range(steps):\n",
    "            ps[step, :] = [(2 / (steps - 1)) * step - 1]\n",
    "\n",
    "        ps_expand = K.expand_dims(K.constant(ps), axis=0)\n",
    "        ps_tiled = K.tile(ps_expand, [K.shape(x)[0], 1, 1])\n",
    "\n",
    "        x = K.concatenate([x, ps_tiled], axis=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def eval(model, X_test, y_test, **kwargs):\n",
    "    ts = TimeseriesGenerator(X_test,\n",
    "                             y_test,\n",
    "                             kwargs.get('sequence_length', 100),\n",
    "                             batch_size=32,\n",
    "                             shuffle=False)\n",
    "    y_true = np.concatenate([y for x, y in ts])\n",
    "    y_pred = np.argmax(model.predict(ts), -1)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return classification_report(y_true, y_pred,\n",
    "                                 output_dict=True)['weighted avg']['f1-score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptionsClass:\n",
    "    \"\"\"\n",
    "    make only lover case parametrs and not start with _\n",
    "    All this methods (exept __call__) only for beauty representation :)\n",
    "    \"\"\"\n",
    "    _unpack_dicts_ = False\n",
    "\n",
    "    def __call__(self, **kwargs: dict):\n",
    "        \"\"\"\n",
    "        Set up parametrs\n",
    "        \"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            self.__setattr__(key, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        key_list = []\n",
    "        for composite_key, value in self.Options.items():\n",
    "            add_str = f'{composite_key}: '\n",
    "\n",
    "            if isinstance(value, np.ndarray | range):\n",
    "                value_str = f'[{value[0]}, {value[1]} .. {value[-2]}, {value[-1]}]; len = {len(value)}'\n",
    "\n",
    "            else:\n",
    "                value_str = f'{value}'\n",
    "\n",
    "            key_list.append(add_str + value_str)\n",
    "        return str('\\n'.join(key_list))\n",
    "\n",
    "    @property\n",
    "    def Options(self):\n",
    "        \"\"\"\n",
    "        Containing options dict\n",
    "        \"\"\"\n",
    "        return {\n",
    "            compound_key.strip(): value\n",
    "            for value, compound_key in self._recursion_view()\n",
    "        }\n",
    "\n",
    "    def _all_options(self):\n",
    "        data_filter = lambda x: (x[0] != '_') and x[0].islower()\n",
    "        options = list(filter(data_filter, self.__dir__()))\n",
    "        return {option: self.__getattribute__(option) for option in options}\n",
    "\n",
    "    def _recursion_view(self, composite_key=''):\n",
    "        \"\"\"\n",
    "        Need for recursion representation containing options\n",
    "        \"\"\"\n",
    "        dilimiter = '  '\n",
    "        if isinstance(self, OptionsClass):\n",
    "            for key in self._all_options():\n",
    "                for inner_key in OptionsClass._recursion_view(\n",
    "                        self.__getattribute__(key),\n",
    "                        str(composite_key) + dilimiter + str(key),\n",
    "                ):\n",
    "                    yield inner_key\n",
    "\n",
    "        # Dicts store as dicts and include in composite key\n",
    "        # (to unpack dicts - uncomment below):\n",
    "\n",
    "        elif isinstance(self, dict) and OptionsClass._unpack_dicts_:\n",
    "            for key in self:\n",
    "                for inner_key in OptionsClass._recursion_view(\n",
    "                        self[key],\n",
    "                        str(composite_key) + dilimiter + str(key),\n",
    "                ):\n",
    "                    yield inner_key\n",
    "\n",
    "        else:\n",
    "            yield (self, composite_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad9525",
   "metadata": {},
   "outputs": [],
   "source": [
    " # def __str__(self):\n",
    "    #     key_list = []\n",
    "    #     options= {\n",
    "    #         compound_key.strip(): value\n",
    "    #         for value, compound_key in self._recursion_view()\n",
    "    #     }\n",
    "    #     for composite_key, value in options.items():\n",
    "    #         add_str = f'{composite_key}: '\n",
    "\n",
    "    #         if isinstance(value, np.ndarray | range):\n",
    "    #             value_str = f'[{value[0]}, {value[1]} .. {value[-2]}, {value[-1]}]; len = {len(value)}'\n",
    "\n",
    "    #         else:\n",
    "    #             value_str = f'{value}'\n",
    "\n",
    "    #         key_list.append(add_str + value_str)\n",
    "    #     return str('\\n'.join(key_list))\n",
    "        \n",
    "    # def _recursion_view(self, composite_key=''):\n",
    "        # \"\"\"\n",
    "        # Need for recursion representation containing options\n",
    "        # \"\"\"\n",
    "        # dilimiter = '  '\n",
    "        # if isinstance(self, OptionsClass):\n",
    "        #     for key in self._get_all_options():\n",
    "        #         for inner_key in OptionsClass._recursion_view(\n",
    "        #                 self.__getattribute__(key),\n",
    "        #                 str(composite_key) + dilimiter + str(key),\n",
    "        #         ):\n",
    "        #             yield inner_key\n",
    "\n",
    "        # # Dicts store as dicts and include in composite key\n",
    "        # # (to unpack dicts - uncomment below):\n",
    "\n",
    "        # elif isinstance(self, dict) and OptionsClass._unpack_dicts_:\n",
    "        #     for key in self:\n",
    "        #         for inner_key in OptionsClass._recursion_view(\n",
    "        #                 self[key],\n",
    "        #                 str(composite_key) + dilimiter + str(key),\n",
    "        #         ):\n",
    "        #             yield inner_key\n",
    "\n",
    "        # else:\n",
    "        #     yield (self, composite_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaed67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass:\n",
    "    \"\"\"\n",
    "    make only lover case parametrs and not start with _\n",
    "    All this methods (exept __call__) only for beauty representation :)\n",
    "    \"\"\"\n",
    "    _data_filter = lambda x: (x[0] != '_') and ('Data' not in x)\n",
    "\n",
    "    def __new__(\n",
    "        cls,\n",
    "        target_dict: dict = None,\n",
    "        name: str='',\n",
    "    ):\n",
    "        if target_dict is not None:\n",
    "            result =DataClass()\n",
    "            return result._rec_build_(name, target_dict)\n",
    "        return super().__new__(cls)\n",
    "    \n",
    "    def __call__(self, **kwargs: dict):\n",
    "        \"\"\"\n",
    "        Set up parametrs\n",
    "        \"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            self.__setattr__(key, value)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Representation of options\n",
    "        \"\"\"\n",
    "        return DataClass._rec_print_(self.Data)\n",
    "\n",
    "    @property\n",
    "    def Data(self):\n",
    "        \"\"\"\n",
    "        Containing options dict\n",
    "        \"\"\"\n",
    "        return self._rec_dict_()\n",
    "\n",
    "    def _get_all_options(self):\n",
    "        # Add except fields\n",
    "\n",
    "        options = list(filter(DataClass._data_filter, self.__dir__()))\n",
    "        return options\n",
    "\n",
    "    def _rec_dict_(self, self_name=None):\n",
    "        if not isinstance(self, DataClass):\n",
    "            return {self_name: self}\n",
    "\n",
    "        result = {}\n",
    "        for option in self._get_all_options():\n",
    "\n",
    "            inner_dict = DataClass._rec_dict_(\n",
    "                self.__getattribute__(option),\n",
    "                option,\n",
    "            )\n",
    "            result.update(inner_dict)\n",
    "\n",
    "        if self_name is None:\n",
    "            return result\n",
    "        else:\n",
    "            return {self_name: result}\n",
    "\n",
    "    @staticmethod\n",
    "    def _rec_print_(target, margin: str = ''):\n",
    "        if not isinstance(target, dict):\n",
    "            return f'{target}'\n",
    "        result = margin\n",
    "\n",
    "        for key, value in target.items():\n",
    "            inner_string = DataClass._rec_print_(\n",
    "                value,\n",
    "                margin + ' ' * 4,\n",
    "            )\n",
    "            result += '\\n' + margin + f'{key}: {inner_string}'\n",
    "\n",
    "        if margin == '':\n",
    "            return result[1:]\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def _rec_build_(self, self_name: str, target):\n",
    "        if not isinstance(target, dict):\n",
    "            self.__setattr__(self_name, target)\n",
    "            return\n",
    "        \n",
    "        result = DataClass()\n",
    "        self.__setattr__(self_name, result)\n",
    "        \n",
    "\n",
    "        for name, inner_target in target.items():\n",
    "            inner_result = result._rec_build_(\n",
    "                name,\n",
    "                inner_target,\n",
    "            )\n",
    "            if inner_result is not None:\n",
    "                self.__setattr__(self_name, inner_result)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c504571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parametrs\n",
    "seq_len = 100\n",
    "\n",
    "class CN_pars(DataClass):\n",
    "    n_filters=14\n",
    "    dilation_steps=4  # dilation = 2**dilation_step\n",
    "\n",
    "class AN_pars(DataClass):\n",
    "    attention_heads = 1\n",
    "    blocks = 2\n",
    "    share_weights = True\n",
    "\n",
    "class FF_pars(DataClass):\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "class Optimaser_pars(DataClass):\n",
    "    lr = 0.0001\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "\n",
    "class Trainig_pars(DataClass):\n",
    "    batch_size = 512\n",
    "    epochs = 150\n",
    "    \n",
    "class Full_pars(DataClass):\n",
    "    cn= CN_pars()\n",
    "    an = AN_pars()\n",
    "    ff=FF_pars()\n",
    "    optimazer=Optimaser_pars()\n",
    "    training=Trainig_pars()\n",
    "    \n",
    "pars= Full_pars() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c504571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model parametrs\n",
    "# seq_len = 100\n",
    "\n",
    "# cn_pars1 = dict(\n",
    "#     n_filters=14,\n",
    "#     dilation_steps=4,\n",
    "# )  # dilation = 2**dilation_step\n",
    "\n",
    "# # AN\n",
    "# attention_heads = 1\n",
    "# blocks = 2\n",
    "# share_weights = True\n",
    "\n",
    "# # FF\n",
    "# dropout_rate = 0.1\n",
    "\n",
    "# # Optimizer\n",
    "# lr = 0.0001\n",
    "# adam_beta1 = 0.9\n",
    "# adam_beta2 = 0.999\n",
    "\n",
    "# # Training\n",
    "# batch_size = 512\n",
    "# epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83adfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "# Input\n",
    "inputs = Input(shape=(seq_len, 40))\n",
    "x = inputs\n",
    "\n",
    "# CN\n",
    "dilation_steps = [2**dilation for dilation in range(pars.cn.dilation_steps + 1)]\n",
    "for dilation in dilation_steps:\n",
    "    x = layers.Conv1D(\n",
    "        filters=pars.cn.n_filters,\n",
    "        kernel_size=2,\n",
    "        dilation_rate=dilation,\n",
    "        activation='relu',\n",
    "        padding='causal',\n",
    "    )(x)\n",
    "# Normalisation\n",
    "norm = layers.LayerNormalization()(x)\n",
    "x=norm\n",
    "\n",
    "# Positional encoding\n",
    "pos = PositionalEncodingLayer()(x)\n",
    "x = pos\n",
    "\n",
    "# Transformers\n",
    "tb = TransformerBlock(\n",
    "    'transformer_block',\n",
    "    pars.an.attention_heads,\n",
    "    True,\n",
    ")\n",
    "for block in range(pars.an.blocks):\n",
    "    if pars.an.share_weights:\n",
    "        x = tb(x)\n",
    "    else:\n",
    "        x = TransformerBlock(\n",
    "            f'transformer_block_{block}',\n",
    "            pars.an.attention_heads,\n",
    "            True,\n",
    "        )(x)\n",
    "\n",
    "# FFN\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64,\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer='l2',\n",
    "                 kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Dropout(pars.ff.dropout_rate)(x)\n",
    "out = layers.Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "# CompiLe\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.Adam(\n",
    "        learning_rate=pars.optimazer.lr,\n",
    "        beta_1=pars.optimazer.adam_beta1,\n",
    "        beta_2=pars.optimazer.adam_beta2,\n",
    "        name=\"Adam\",\n",
    "    ),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "print(\n",
    "    f'Train x: {str(x_train.shape): <15} - y: {y_train.shape}',\n",
    "    f'Val   x: {str(x_val.shape): <15} - y: {y_val.shape}',\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b00f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_shape(value_x,value_y):\n",
    "    value_x.set_shape((None,100,40))\n",
    "    # value_y.set_shape((None,))\n",
    "    return value_x,value_y\n",
    "\n",
    "ds_train = timeseries_dataset_from_array(\n",
    "    data=x_train,\n",
    "    targets=y_train,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    sequence_length=seq_len,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_train= ds_train.map(set_shape)\n",
    "\n",
    "ds_val = timeseries_dataset_from_array(\n",
    "    data=x_val,\n",
    "    targets=y_val,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    sequence_length=seq_len,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_val= ds_val.map(set_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=pars.training.epochs,\n",
    "    validation_data=ds_val,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('translob_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a9191c6b2d33302590e376f8aee71d3c7e87a446da0bda5474eb7c47655c891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
