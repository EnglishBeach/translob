{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a70cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from LobTransformer import TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01beb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# download FI2010 dataset from \n",
    "# https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649\n",
    "FI2010_DIR = r'D:\\WORKS\\translob\\dataset\\BenchmarkDatasets'\n",
    "\n",
    "def gen_data(data, horizon):\n",
    "    x = data[:40, :].T  # 40 == 10 price + volume asks + 10 price + volume bids\n",
    "    # FIXME: delete .T\n",
    "    y = data[-5 + horizon, :].T  # 5\n",
    "    return x[:-1], (y[1:] - 1).astype(np.int32)  # shift y by 1\n",
    "\n",
    "\n",
    "def load_dataset(horizon):\n",
    "    dec_data = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt'\n",
    "    )\n",
    "    dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "    dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "    dec_test1 = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_7.txt'\n",
    "    )\n",
    "    dec_test2 = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_8.txt'\n",
    "    )\n",
    "    dec_test3 = np.loadtxt(\n",
    "        f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "    )\n",
    "    dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "    result = (\n",
    "        gen_data(dec_train,horizon), \n",
    "        gen_data(dec_val,horizon), \n",
    "        gen_data(dec_test, horizon)) #yapf: disable\n",
    "    return result\n",
    "\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_dataset(horizon=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef29505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3482.5004661 ,  152.23163124, 3474.47744336,   93.861558  ,\n",
       "       3492.09621333,   43.0617752 , 3475.4918844 ,  304.13057864,\n",
       "       3493.90835021,   23.33160192, 3477.74077363,  371.2583808 ,\n",
       "       3498.510855  ,   37.064136  , 3479.84899444,  315.66830497,\n",
       "       3503.08739616,    8.46771822, 3489.91982907,   44.21806086,\n",
       "       3473.94724562,  172.09740816, 3444.77629104,  153.94877388,\n",
       "       3469.64402948,  256.30380036, 3438.396936  ,  252.912781  ,\n",
       "       3463.57411355,  105.88077597, 3431.21806785,   39.043824  ,\n",
       "       3458.11757754,   76.03908312, 3423.25964425,   61.09721826,\n",
       "       3455.97596592,   71.14003521, 3389.51349707,   64.3653376 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test of fi2020 module from start\n",
    "# a = np.array([\n",
    "#     2615, 353, 2618, 200, 2619, 164, 2620, 532, 2621, 151, 2623, 837, 2625,\n",
    "#     150, 2626, 787, 2629, 146, 2633, 311, 2606, 326, 2604, 682, 2602, 786,\n",
    "#     2600, 893, 2599, 159, 2595, 100, 2593, 143, 2591, 134, 2588, 123, 2579, 128\n",
    "# ])\n",
    "# x_train[0]*a+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc422b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eef9034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PositionalEncodingLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, *args, **kwargs):\n",
    "        steps, d_model = x.get_shape()[-2:]\n",
    "        global A \n",
    "        A= x,steps,d_model\n",
    "        ps = np.zeros([steps, 1], dtype=K.floatx())\n",
    "        for step in range(steps):\n",
    "            ps[step, :] = [(2 / (steps - 1)) * step - 1]\n",
    "\n",
    "        ps_expand = K.expand_dims(K.constant(ps), axis=0)\n",
    "        ps_tiled = K.tile(ps_expand, [K.shape(x)[0], 1, 1])\n",
    "\n",
    "        x = K.concatenate([x, ps_tiled], axis=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def eval(model, X_test, y_test, **kwargs):\n",
    "    ts = TimeseriesGenerator(X_test,\n",
    "                             y_test,\n",
    "                             kwargs.get('sequence_length', 100),\n",
    "                             batch_size=32,\n",
    "                             shuffle=False)\n",
    "    y_true = np.concatenate([y for x, y in ts])\n",
    "    y_pred = np.argmax(model.predict(ts), -1)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return classification_report(y_true, y_pred,\n",
    "                                 output_dict=True)['weighted avg']['f1-score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c504571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrs\n",
    "seq_len = 100\n",
    "n_filters = 14\n",
    "dilation_steps = 4 # max dilation = 2**dilation_steps\n",
    "attention_heads = 1\n",
    "blocks = 2\n",
    "share_weights = True\n",
    "dropout_rate = 0.1\n",
    "lr = 0.0001\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "batch_size = 512\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83adfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 40)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 100, 14)              1134      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 100, 14)              406       ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 100, 14)              406       ['conv1d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 100, 14)              406       ['conv1d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 100, 14)              406       ['conv1d_3[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 100, 14)              28        ['conv1d_4[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " positional_encoding_layer   (None, 100, 15)              0         ['layer_normalization[0][0]'] \n",
      " (PositionalEncodingLayer)                                                                        \n",
      "                                                                                                  \n",
      " transformer_block (Transfo  (None, 100, 15)              2610      ['positional_encoding_layer[0]\n",
      " rmerBlock)                                                         [0]',                         \n",
      "                                                                     'transformer_block[0][0]']   \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1500)                 0         ['transformer_block[1][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   96064     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 3)                    195       ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 101655 (397.09 KB)\n",
      "Trainable params: 101655 (397.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Train (203799, 40) (203799,) Val (50949, 40) (50949,)\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "inputs = Input(shape=(seq_len, 40))\n",
    "x = inputs\n",
    "for dilation in [2**dilation for dilation in range(dilation_steps + 1)]:\n",
    "    x = layers.Conv1D(\n",
    "        n_filters,\n",
    "        kernel_size=2,\n",
    "        dilation_rate=dilation,\n",
    "        activation='relu',\n",
    "        padding='causal',\n",
    "    )(x)\n",
    "\n",
    "norm = layers.LayerNormalization()(x)\n",
    "x=norm\n",
    "pos = PositionalEncodingLayer()(x)\n",
    "x = pos\n",
    "tb = TransformerBlock(\n",
    "    'tb1',\n",
    "    attention_heads,\n",
    "    True,\n",
    ")\n",
    "blocks = blocks\n",
    "for block in range(blocks):\n",
    "    if share_weights:\n",
    "        x = tb(x)\n",
    "    else:\n",
    "        x = TransformerBlock(\n",
    "            f'transformer_block_{block}',\n",
    "            attention_heads,\n",
    "            True,\n",
    "        )(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64,\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer='l2',\n",
    "                 kernel_initializer='glorot_uniform')(x)\n",
    "x = layers.Dropout(dropout_rate)(x)\n",
    "out = layers.Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.Adam(\n",
    "        learning_rate=lr,\n",
    "        beta_1=adam_beta1,\n",
    "        beta_2=adam_beta2,\n",
    "        name=\"Adam\",\n",
    "    ),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "print(\n",
    "    'Train',\n",
    "    x_train.shape,\n",
    "    y_train.shape,\n",
    "    'Val',\n",
    "    x_val.shape,\n",
    "    y_val.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83a125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = TimeseriesGenerator(\n",
    "#     data= x_train,\n",
    "#     targets=y_train,\n",
    "#     length=seq_len,\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size,\n",
    "# )\n",
    "# val_gen = TimeseriesGenerator(\n",
    "#     data= x_val,\n",
    "#     targets=y_val,\n",
    "#     length=seq_len,\n",
    "#     batch_size=batch_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77b1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a2b00f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 20370, 'error': 0}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=10\n",
    "\n",
    "ds_train = timeseries_dataset_from_array(\n",
    "    data=x_train,\n",
    "    targets=y_train,\n",
    "    batch_size=v,\n",
    "    sequence_length=seq_len,\n",
    "    # shuffle=True,\n",
    ")\n",
    "# x= timeseries_dataset_from_array(x_train,None,\n",
    "\n",
    "#     batch_size=2,\n",
    "#     sequence_length=seq_len,\n",
    "# )\n",
    "# y =timeseries_dataset_from_array(y_train,None,\n",
    "#     batch_size=2,\n",
    "#     sequence_length=seq_len,\n",
    "# )\n",
    "# ds_val = timeseries_dataset_from_array(\n",
    "#     data=x_val,\n",
    "#     targets=y_val,\n",
    "#     batch_size=batch_size,\n",
    "#     sequence_length=seq_len,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "\n",
    "# Not working:\n",
    "def foo(x,self):\n",
    "    return tf.ensure_shape(x, [None,v,40])\n",
    "ds_train.map(\n",
    "    foo\n",
    "    )\n",
    "count={'step':0,'error':0}\n",
    "for i in ds_train:\n",
    "    if i[0].shape!=[v,100,40]:count['error']+=1\n",
    "    count['step']+=1\n",
    "    n= i\n",
    "    # if count>396: break\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3f7c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    if len(x.shape)==1:\n",
    "       gen_dim =1\n",
    "    else:\n",
    "        gen_dim = x.shape[-1]\n",
    "    \n",
    "    line = range(len(x) - 100)\n",
    "    iterable = (x[i:i + 100] for i in line)\n",
    "    a = np.fromiter(\n",
    "        iter=iterable,\n",
    "        dtype=(np.float64, (100, gen_dim)),\n",
    "        count=len(line),\n",
    "    )\n",
    "    \n",
    "    line = range(0, len(a) - 512 + 1, 512)\n",
    "    iterable = (a[i:i + 512] for i in line)\n",
    "    b = np.fromiter(\n",
    "        iter=iterable,\n",
    "        dtype=(np.float64, (512, 100, gen_dim)),\n",
    "        count=len(line),\n",
    "    )\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7036d6c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must specify length when using variable-size data-type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m by \u001b[39m=\u001b[39mfoo(y_test)\n",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m, in \u001b[0;36mfoo\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x) \u001b[39m-\u001b[39m \u001b[39m100\u001b[39m)\n\u001b[0;32m      8\u001b[0m iterable \u001b[39m=\u001b[39m (x[i:i \u001b[39m+\u001b[39m \u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m line)\n\u001b[1;32m----> 9\u001b[0m a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromiter(\n\u001b[0;32m     10\u001b[0m     \u001b[39miter\u001b[39;49m\u001b[39m=\u001b[39;49miterable,\n\u001b[0;32m     11\u001b[0m     dtype\u001b[39m=\u001b[39;49m(np\u001b[39m.\u001b[39;49mfloat64, (\u001b[39m100\u001b[39;49m, gen_dim)),\n\u001b[0;32m     12\u001b[0m     count\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(line),\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(a) \u001b[39m-\u001b[39m \u001b[39m512\u001b[39m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m512\u001b[39m)\n\u001b[0;32m     16\u001b[0m iterable \u001b[39m=\u001b[39m (a[i:i \u001b[39m+\u001b[39m \u001b[39m512\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m line)\n",
      "\u001b[1;31mValueError\u001b[0m: Must specify length when using variable-size data-type."
     ]
    }
   ],
   "source": [
    "by =foo(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0335cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= foo(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3cd03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/398 [00:00<00:25, 15.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_gen = keras.preprocessing.sequence.TimeseriesGenerator(\n",
    "    data= x_train,\n",
    "    targets=y_train,\n",
    "    length=seq_len,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_gen = keras.preprocessing.sequence.TimeseriesGenerator(\n",
    "    data= x_val,\n",
    "    targets=y_val,\n",
    "    length=seq_len,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "X_train,Y_train = train_gen[0]\n",
    "dataset = tqdm(iterable=train_gen)\n",
    "num = 0\n",
    "for i in dataset:\n",
    "    X_train = np.vstack([X_train,i[0]])\n",
    "    Y_train = np.hstack([Y_train,i[1]])\n",
    "    num +=1\n",
    "    if num>10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462cd96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 10s 545ms/step - loss: 2.4305 - sparse_categorical_accuracy: 0.3950\n",
      "Epoch 2/150\n",
      " 3/12 [======>.......................] - ETA: 5s - loss: 2.3187 - sparse_categorical_accuracy: 0.4076"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     x\u001b[39m=\u001b[39;49mX_train,\n\u001b[0;32m      3\u001b[0m     y\u001b[39m=\u001b[39;49mY_train,\n\u001b[0;32m      4\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m      6\u001b[0m     \u001b[39m# validation_data=ds_val,\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m     \u001b[39m# callbacks=[\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39m#     tf.keras.callbacks.TensorBoard(\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39m#         log_dir=(\"logs/scalars/\" +\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39m#                  datetime.now().strftime(\"%Y%m%d-%H%M%S\")), ),\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m     \u001b[39m#     tf.keras.callbacks.EarlyStopping(\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39m#         monitor='val_sparse_categorical_accuracy',\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m#         mode='max',\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m     \u001b[39m#         patience=10,\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m     \u001b[39m#         min_delta=0.0002,\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m     \u001b[39m#     ),\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m     \u001b[39m#     # ModelCheckpoint('mdl.hdf5', save_best_only=True, monitor='val_loss', mode='min'),\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m     \u001b[39m# ],\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    # validation_data=ds_val,\n",
    "    # callbacks=[\n",
    "    #     tf.keras.callbacks.TensorBoard(\n",
    "    #         log_dir=(\"logs/scalars/\" +\n",
    "    #                  datetime.now().strftime(\"%Y%m%d-%H%M%S\")), ),\n",
    "    #     tf.keras.callbacks.EarlyStopping(\n",
    "    #         monitor='val_sparse_categorical_accuracy',\n",
    "    #         mode='max',\n",
    "    #         patience=10,\n",
    "    #         min_delta=0.0002,\n",
    "    #     ),\n",
    "    #     # ModelCheckpoint('mdl.hdf5', save_best_only=True, monitor='val_loss', mode='min'),\n",
    "    # ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('translob_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a9191c6b2d33302590e376f8aee71d3c7e87a446da0bda5474eb7c47655c891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
