{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a70cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from keras import Input, Model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.regularizers import L2\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from LobTransformer import TransformerBlock\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# download FI2010 dataset from https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649\n",
    "\n",
    "FI2010_DIR=r'D:\\WORKS\\translob\\dataset\\BenchmarkDatasets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eef9034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PositionalEncodingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, *args, **kwargs):\n",
    "        steps, d_model = x.get_shape().as_list()[-2:]\n",
    "        ps = np.zeros([steps, 1], dtype=K.floatx())\n",
    "        for tx in range(steps):\n",
    "            ps[tx, :] = [(2 / (steps - 1)) * tx - 1]\n",
    "\n",
    "        ps_expand = K.expand_dims(K.constant(ps), axis=0)\n",
    "        ps_tiled = K.tile(ps_expand, [K.shape(x)[0], 1, 1])\n",
    "\n",
    "        x = K.concatenate([x, ps_tiled], axis=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def translob_model(**kwargs):\n",
    "    inputs = Input(shape=(kwargs.get('sequence_length', 100), 40))\n",
    "    x = inputs\n",
    "    max_conv_filters = kwargs.get('num_conv_filters', 14)\n",
    "    max_conv_dilation = kwargs.get('max_conv_dilation', 16)\n",
    "    for dilation in [2 ** v for v in list(range(math.ceil(math.log2(max_conv_dilation)) + 1))]:\n",
    "        x = layers.Conv1D(\n",
    "            max_conv_filters, kernel_size=2, dilation_rate=dilation, activation='relu', padding='causal'\n",
    "        )(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = PositionalEncodingLayer()(x)\n",
    "    tb = TransformerBlock('tb1', kwargs.get('num_attention_heads', 3), True)\n",
    "    blocks = kwargs.get('num_transformer_blocks', 2)\n",
    "    for block in range(blocks):\n",
    "        if kwargs.get('transformer_blocks_share_weights', True):\n",
    "            x = tb(x)\n",
    "        else:\n",
    "            x = TransformerBlock(f'transformer_block_{block}', kwargs.get('num_attention_heads', 3), True)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, \n",
    "                     activation='relu', \n",
    "                     kernel_regularizer='l2', \n",
    "                     kernel_initializer='glorot_uniform')(x)\n",
    "    x = layers.Dropout(kwargs.get('dropout_rate', 0.1))(x)\n",
    "    out = layers.Dense(3, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        tf.keras.optimizers.Adam(\n",
    "            learning_rate=kwargs.get('lr', 0.0001),\n",
    "            beta_1=kwargs.get('adam_beta1', 0.9),\n",
    "            beta_2=kwargs.get('adam_beta2', 0.999),\n",
    "            name=\"Adam\",\n",
    "        ),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['sparse_categorical_accuracy'],\n",
    "    )\n",
    "    return model\n",
    "                        \n",
    "\n",
    "def train_translob(X_train, y_train, X_val, y_val, **kwargs):\n",
    "    print('Train', X_train.shape, y_train.shape, 'Val', X_val.shape, y_val.shape)\n",
    "    model = translob_model(**kwargs)\n",
    "\n",
    "    length = kwargs.get('sequence_length', 100)\n",
    "    train_gen = TimeseriesGenerator(X_train, y_train, length, shuffle=True, batch_size=kwargs.get('batch_size', 32))\n",
    "    val_gen = TimeseriesGenerator(X_val, y_val, length, batch_size=kwargs.get('batch_size', 32))\n",
    "\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        epochs=kwargs.get('epochs', 100),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=(\n",
    "                    \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', mode='max', patience=10, min_delta=0.0002),\n",
    "#             ModelCheckpoint('mdl.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "        ],\n",
    "        validation_data=val_gen\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def gen_data(data, horizon):\n",
    "    x = data[:40, :].T  # 40 == 10 price + volume asks + 10 price + volume bids\n",
    "    y = data[-5 + horizon, :].T  # 5\n",
    "    return x[:-1], (y[1:] - 1).astype(np.int32)  # shift y by 1\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(horizon):\n",
    "    dec_data = np.loadtxt(f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "    dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "    dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "    dec_test1 = np.loadtxt(f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_7.txt')\n",
    "    dec_test2 = np.loadtxt(f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_8.txt')\n",
    "    dec_test3 = np.loadtxt(f'{FI2010_DIR}/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_9.txt')\n",
    "    dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "    return gen_data(dec_train, horizon), gen_data(dec_val, horizon), gen_data(dec_test, horizon)\n",
    "\n",
    "\n",
    "def eval(model, X_test, y_test, **kwargs):\n",
    "    ts = TimeseriesGenerator(X_test, y_test, kwargs.get('sequence_length', 100), batch_size=32, shuffle=False)\n",
    "    y_true = np.concatenate([y for x, y in ts])\n",
    "    y_pred = np.argmax(model.predict(ts), -1)\n",
    "    print(classification_report(y_true, y_pred))    \n",
    "    return classification_report(y_true, y_pred, output_dict=True)['weighted avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943788a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_dataset(horizon=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c504571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    # inputs\n",
    "    'sequence_length': 100,\n",
    "    # model\n",
    "    'num_conv_filters': 14,\n",
    "    'max_conv_dilation': 16,\n",
    "    'num_attention_heads': 3,\n",
    "    'num_transformer_blocks': 2,\n",
    "    'transformer_blocks_share_weights': True, \n",
    "    'dropout_rate': 0.1,\n",
    "    # training\n",
    "    'lr': 0.0001,\n",
    "    'adam_beta1': 0.9,\n",
    "    'adam_beta2': 0.999,\n",
    "    'batch_size': 32,\n",
    "    # 'batch_size': 512,\n",
    "    'epochs': 150\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80866b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (203799, 40) (203799,) Val (50949, 40) (50949,)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 100, 40)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 100, 14)              1134      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 100, 14)              406       ['conv1d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 100, 14)              406       ['conv1d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 100, 14)              406       ['conv1d_17[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)          (None, 100, 14)              406       ['conv1d_18[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 100, 14)              28        ['conv1d_19[0][0]']           \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " positional_encoding_layer_  (None, 100, 15)              0         ['layer_normalization_3[0][0]'\n",
      " 3 (PositionalEncodingLayer                                         ]                             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " transformer_block_3 (Trans  (None, 100, 15)              2610      ['positional_encoding_layer_3[\n",
      " formerBlock)                                                       0][0]',                       \n",
      "                                                                     'transformer_block_3[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 1500)                 0         ['transformer_block_3[1][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 64)                   96064     ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 64)                   0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 3)                    195       ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 101655 (397.09 KB)\n",
      "Trainable params: 101655 (397.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\HOME\\AppData\\Local\\Temp\\__autograph_generated_fileuwhtt7f3.py\", line 11, in tf__call\n        ps = ag__.converted_call(ag__.ld(np).zeros, ([ag__.ld(steps), 1],), dict(dtype=ag__.converted_call(ag__.ld(K).floatx, (), None, fscope)), fscope)\n\n    TypeError: Exception encountered when calling layer 'positional_encoding_layer_3' (type PositionalEncodingLayer).\n    \n    in user code:\n    \n        File \"C:\\Users\\HOME\\AppData\\Local\\Temp\\ipykernel_3284\\449431768.py\", line 7, in call  *\n            ps = np.zeros([steps, 1], dtype=K.floatx())\n    \n        TypeError: 'NoneType' object cannot be interpreted as an integer\n    \n    \n    Call arguments received by layer 'positional_encoding_layer_3' (type PositionalEncodingLayer):\n      • x=tf.Tensor(shape=(None, None, 14), dtype=float32)\n      • args=<class 'inspect._empty'>\n      • kwargs={'training': 'True'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m train_translob(X_train, y_train, X_val, y_val, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m      2\u001b[0m \u001b[39meval\u001b[39m(model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m      3\u001b[0m \u001b[39meval\u001b[39m(model, X_test, y_test, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m, in \u001b[0;36mtrain_translob\u001b[1;34m(X_train, y_train, X_val, y_val, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     train_gen \u001b[39m=\u001b[39m TimeseriesGenerator(X_train, y_train, length, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m32\u001b[39m))\n\u001b[0;32m     65\u001b[0m     val_gen \u001b[39m=\u001b[39m TimeseriesGenerator(X_val, y_val, length, batch_size\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m32\u001b[39m))\n\u001b[1;32m---> 67\u001b[0m     model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     68\u001b[0m         train_gen,\n\u001b[0;32m     69\u001b[0m         epochs\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m100\u001b[39;49m),\n\u001b[0;32m     70\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     71\u001b[0m             tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTensorBoard(log_dir\u001b[39m=\u001b[39;49m(\n\u001b[0;32m     72\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mlogs/scalars/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m datetime\u001b[39m.\u001b[39;49mnow()\u001b[39m.\u001b[39;49mstrftime(\u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     73\u001b[0m             ),\n\u001b[0;32m     74\u001b[0m             tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_sparse_categorical_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, min_delta\u001b[39m=\u001b[39;49m\u001b[39m0.0002\u001b[39;49m),\n\u001b[0;32m     75\u001b[0m \u001b[39m#             ModelCheckpoint('mdl.hdf5', save_best_only=True, monitor='val_loss', mode='min')\u001b[39;49;00m\n\u001b[0;32m     76\u001b[0m         ],\n\u001b[0;32m     77\u001b[0m         validation_data\u001b[39m=\u001b[39;49mval_gen\n\u001b[0;32m     78\u001b[0m     )\n\u001b[0;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filed6fxm6sh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileuwhtt7f3.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m steps, d_model \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(x)\u001b[39m.\u001b[39mget_shape, (), \u001b[39mNone\u001b[39;00m, fscope)\u001b[39m.\u001b[39mas_list, (), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m---> 11\u001b[0m ps \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(np)\u001b[39m.\u001b[39;49mzeros, ([ag__\u001b[39m.\u001b[39;49mld(steps), \u001b[39m1\u001b[39;49m],), \u001b[39mdict\u001b[39;49m(dtype\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49mfloatx, (), \u001b[39mNone\u001b[39;49;00m, fscope)), fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m ()\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\HOME\\AppData\\Local\\Temp\\__autograph_generated_fileuwhtt7f3.py\", line 11, in tf__call\n        ps = ag__.converted_call(ag__.ld(np).zeros, ([ag__.ld(steps), 1],), dict(dtype=ag__.converted_call(ag__.ld(K).floatx, (), None, fscope)), fscope)\n\n    TypeError: Exception encountered when calling layer 'positional_encoding_layer_3' (type PositionalEncodingLayer).\n    \n    in user code:\n    \n        File \"C:\\Users\\HOME\\AppData\\Local\\Temp\\ipykernel_3284\\449431768.py\", line 7, in call  *\n            ps = np.zeros([steps, 1], dtype=K.floatx())\n    \n        TypeError: 'NoneType' object cannot be interpreted as an integer\n    \n    \n    Call arguments received by layer 'positional_encoding_layer_3' (type PositionalEncodingLayer):\n      • x=tf.Tensor(shape=(None, None, 14), dtype=float32)\n      • args=<class 'inspect._empty'>\n      • kwargs={'training': 'True'}\n"
     ]
    }
   ],
   "source": [
    "model = train_translob(X_train, y_train, X_val, y_val, **params)\n",
    "eval(model, X_val, y_val, **params)\n",
    "eval(model, X_test, y_test, **params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb2ed9",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e809a900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-25 17:36:05,346]\u001b[0m A new study created in memory with name: no-name-1164c60e-3544-428a-8f8b-b6ba658cd6de\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (203799, 40) (203799,) Val (50949, 40) (50949,)\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 100, 40)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 100, 14)           1134      \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "layer_normalization_14 (Laye (None, 100, 14)           28        \n",
      "_________________________________________________________________\n",
      "positional_encoding_layer_14 (None, 100, 15)           0         \n",
      "_________________________________________________________________\n",
      "transformer_block_20 (Transf (None, 100, 15)           2610      \n",
      "_________________________________________________________________\n",
      "transformer_block_21 (Transf (None, 100, 15)           2610      \n",
      "_________________________________________________________________\n",
      "transformer_block_22 (Transf (None, 100, 15)           2610      \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                96064     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 107,281\n",
      "Trainable params: 107,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer TransformerBlock has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/150\n",
      "796/796 [==============================] - 32s 35ms/step - loss: 1.4737 - sparse_categorical_accuracy: 0.4113 - val_loss: 1.1048 - val_sparse_categorical_accuracy: 0.3858\n",
      "Epoch 2/150\n",
      "796/796 [==============================] - 27s 33ms/step - loss: 0.9963 - sparse_categorical_accuracy: 0.4435 - val_loss: 1.0401 - val_sparse_categorical_accuracy: 0.4342\n",
      "Epoch 3/150\n",
      "796/796 [==============================] - 29s 36ms/step - loss: 0.9453 - sparse_categorical_accuracy: 0.4691 - val_loss: 0.9974 - val_sparse_categorical_accuracy: 0.4612\n",
      "Epoch 4/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.9262 - sparse_categorical_accuracy: 0.4800 - val_loss: 0.9930 - val_sparse_categorical_accuracy: 0.4633\n",
      "Epoch 5/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.9177 - sparse_categorical_accuracy: 0.4827 - val_loss: 0.9737 - val_sparse_categorical_accuracy: 0.4700\n",
      "Epoch 6/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.9116 - sparse_categorical_accuracy: 0.4844 - val_loss: 0.9698 - val_sparse_categorical_accuracy: 0.4699\n",
      "Epoch 7/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.9047 - sparse_categorical_accuracy: 0.4863 - val_loss: 1.0287 - val_sparse_categorical_accuracy: 0.4522\n",
      "Epoch 8/150\n",
      "796/796 [==============================] - 29s 37ms/step - loss: 0.9048 - sparse_categorical_accuracy: 0.4891 - val_loss: 0.9663 - val_sparse_categorical_accuracy: 0.4770\n",
      "Epoch 9/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 0.8968 - sparse_categorical_accuracy: 0.4893 - val_loss: 0.9575 - val_sparse_categorical_accuracy: 0.4782\n",
      "Epoch 10/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8939 - sparse_categorical_accuracy: 0.4906 - val_loss: 0.9654 - val_sparse_categorical_accuracy: 0.4762\n",
      "Epoch 11/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 0.8874 - sparse_categorical_accuracy: 0.4928 - val_loss: 0.9542 - val_sparse_categorical_accuracy: 0.4803\n",
      "Epoch 12/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 0.8875 - sparse_categorical_accuracy: 0.4943 - val_loss: 0.9621 - val_sparse_categorical_accuracy: 0.4756\n",
      "Epoch 13/150\n",
      "796/796 [==============================] - 26s 32ms/step - loss: 0.8875 - sparse_categorical_accuracy: 0.4965 - val_loss: 0.9555 - val_sparse_categorical_accuracy: 0.4784\n",
      "Epoch 14/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8789 - sparse_categorical_accuracy: 0.4990 - val_loss: 0.9520 - val_sparse_categorical_accuracy: 0.4797\n",
      "Epoch 15/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 0.8770 - sparse_categorical_accuracy: 0.4996 - val_loss: 0.9564 - val_sparse_categorical_accuracy: 0.4801\n",
      "Epoch 16/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8767 - sparse_categorical_accuracy: 0.4987 - val_loss: 0.9526 - val_sparse_categorical_accuracy: 0.4835\n",
      "Epoch 17/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.8714 - sparse_categorical_accuracy: 0.5007 - val_loss: 0.9662 - val_sparse_categorical_accuracy: 0.4760\n",
      "Epoch 18/150\n",
      "796/796 [==============================] - 27s 33ms/step - loss: 0.8737 - sparse_categorical_accuracy: 0.4987 - val_loss: 0.9584 - val_sparse_categorical_accuracy: 0.4847\n",
      "Epoch 19/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8711 - sparse_categorical_accuracy: 0.5034 - val_loss: 0.9852 - val_sparse_categorical_accuracy: 0.4821\n",
      "Epoch 20/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.8685 - sparse_categorical_accuracy: 0.5042 - val_loss: 0.9658 - val_sparse_categorical_accuracy: 0.4799\n",
      "Epoch 21/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 0.8672 - sparse_categorical_accuracy: 0.5030 - val_loss: 0.9624 - val_sparse_categorical_accuracy: 0.4859\n",
      "Epoch 22/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.8648 - sparse_categorical_accuracy: 0.5069 - val_loss: 0.9643 - val_sparse_categorical_accuracy: 0.4804\n",
      "Epoch 23/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.8668 - sparse_categorical_accuracy: 0.5033 - val_loss: 0.9597 - val_sparse_categorical_accuracy: 0.4767\n",
      "Epoch 24/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8594 - sparse_categorical_accuracy: 0.5068 - val_loss: 0.9617 - val_sparse_categorical_accuracy: 0.4817\n",
      "Epoch 25/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8603 - sparse_categorical_accuracy: 0.5109 - val_loss: 0.9718 - val_sparse_categorical_accuracy: 0.4823\n",
      "Epoch 26/150\n",
      "796/796 [==============================] - 27s 34ms/step - loss: 0.8583 - sparse_categorical_accuracy: 0.5067 - val_loss: 0.9748 - val_sparse_categorical_accuracy: 0.4847\n",
      "Epoch 27/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8609 - sparse_categorical_accuracy: 0.5060 - val_loss: 0.9602 - val_sparse_categorical_accuracy: 0.4844\n",
      "Epoch 28/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8541 - sparse_categorical_accuracy: 0.5098 - val_loss: 0.9698 - val_sparse_categorical_accuracy: 0.4754\n",
      "Epoch 29/150\n",
      "796/796 [==============================] - 26s 32ms/step - loss: 0.8569 - sparse_categorical_accuracy: 0.5085 - val_loss: 0.9718 - val_sparse_categorical_accuracy: 0.4836\n",
      "Epoch 30/150\n",
      "796/796 [==============================] - 26s 33ms/step - loss: 0.8534 - sparse_categorical_accuracy: 0.5105 - val_loss: 0.9577 - val_sparse_categorical_accuracy: 0.4808\n",
      "Epoch 31/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 26s 32ms/step - loss: 0.8525 - sparse_categorical_accuracy: 0.5116 - val_loss: 0.9737 - val_sparse_categorical_accuracy: 0.4831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.85      0.58     18931\n",
      "           1       0.62      0.63      0.62     13201\n",
      "           2       0.42      0.01      0.02     18717\n",
      "\n",
      "    accuracy                           0.48     50849\n",
      "   macro avg       0.49      0.50      0.41     50849\n",
      "weighted avg       0.48      0.48      0.38     50849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-25 17:50:29,042]\u001b[0m Trial 0 finished with value: 0.4340597140988169 and parameters: {'num_conv_filters': 14, 'max_conv_dilation': 32, 'num_attention_heads': 5, 'num_transformer_blocks': 3, 'transformer_blocks_share_weights': False, 'dropout_rate': 0.2338475471159294, 'learning_rate': 0.0006509155238774959}. Best is trial 0 with value: 0.4340597140988169.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.85      0.57     47913\n",
      "           1       0.72      0.61      0.66     48050\n",
      "           2       0.28      0.02      0.03     43523\n",
      "\n",
      "    accuracy                           0.51    139486\n",
      "   macro avg       0.48      0.49      0.42    139486\n",
      "weighted avg       0.48      0.51      0.43    139486\n",
      "\n",
      "Train (203799, 40) (203799,) Val (50949, 40) (50949,)\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 100, 40)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 100, 14)           1134      \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 100, 14)           406       \n",
      "_________________________________________________________________\n",
      "layer_normalization_15 (Laye (None, 100, 14)           28        \n",
      "_________________________________________________________________\n",
      "positional_encoding_layer_15 (None, 100, 15)           0         \n",
      "_________________________________________________________________\n",
      "transformer_block_24 (Transf (None, 100, 15)           2610      \n",
      "_________________________________________________________________\n",
      "transformer_block_25 (Transf (None, 100, 15)           2610      \n",
      "_________________________________________________________________\n",
      "transformer_block_26 (Transf (None, 100, 15)           2610      \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                96064     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 106,875\n",
      "Trainable params: 106,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer TransformerBlock has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/150\n",
      "796/796 [==============================] - 25s 27ms/step - loss: 1.4460 - sparse_categorical_accuracy: 0.4080 - val_loss: 1.0909 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 2/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 1.0280 - sparse_categorical_accuracy: 0.4153 - val_loss: 1.0903 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 3/150\n",
      "796/796 [==============================] - 19s 24ms/step - loss: 1.0154 - sparse_categorical_accuracy: 0.4138 - val_loss: 1.0899 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 4/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 1.0126 - sparse_categorical_accuracy: 0.4129 - val_loss: 1.0893 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 5/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 1.0084 - sparse_categorical_accuracy: 0.4143 - val_loss: 1.0888 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 6/150\n",
      "796/796 [==============================] - 21s 27ms/step - loss: 1.0065 - sparse_categorical_accuracy: 0.4165 - val_loss: 1.0882 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 7/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 1.0033 - sparse_categorical_accuracy: 0.4155 - val_loss: 1.0881 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 8/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 1.0049 - sparse_categorical_accuracy: 0.4151 - val_loss: 1.0875 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 9/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 1.0006 - sparse_categorical_accuracy: 0.4212 - val_loss: 1.0878 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 10/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 1.0016 - sparse_categorical_accuracy: 0.4136 - val_loss: 1.0869 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 11/150\n",
      "796/796 [==============================] - 20s 26ms/step - loss: 0.9957 - sparse_categorical_accuracy: 0.4180 - val_loss: 1.0871 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 12/150\n",
      "796/796 [==============================] - 20s 25ms/step - loss: 0.9954 - sparse_categorical_accuracy: 0.4149 - val_loss: 1.0868 - val_sparse_categorical_accuracy: 0.3723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54     18931\n",
      "           1       0.00      0.00      0.00     13201\n",
      "           2       0.00      0.00      0.00     18717\n",
      "\n",
      "    accuracy                           0.37     50849\n",
      "   macro avg       0.12      0.33      0.18     50849\n",
      "weighted avg       0.14      0.37      0.20     50849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-07-25 17:54:58,440]\u001b[0m Trial 1 finished with value: 0.2630675492734941 and parameters: {'num_conv_filters': 14, 'max_conv_dilation': 16, 'num_attention_heads': 3, 'num_transformer_blocks': 3, 'transformer_blocks_share_weights': False, 'dropout_rate': 0.2962835591242553, 'learning_rate': 0.001852804968017065}. Best is trial 0 with value: 0.4340597140988169.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.70      0.43     47913\n",
      "           1       0.00      0.00      0.00     48050\n",
      "           2       0.46      0.31      0.37     43523\n",
      "\n",
      "    accuracy                           0.34    139486\n",
      "   macro avg       0.26      0.34      0.27    139486\n",
      "weighted avg       0.25      0.34      0.26    139486\n",
      "\n",
      "Train (203799, 40) (203799,) Val (50949, 40) (50949,)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 100, 40)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 100, 29)      2349        input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 100, 29)      1711        conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 100, 29)      1711        conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 100, 29)      1711        conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 100, 29)      1711        conv1d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 100, 29)      1711        conv1d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 100, 29)      58          conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_layer_16 (P (None, 100, 30)      0           layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_27 (Transform (None, 100, 30)      10170       positional_encoding_layer_16[0][0\n",
      "                                                                 transformer_block_27[0][0]       \n",
      "                                                                 transformer_block_27[1][0]       \n",
      "                                                                 transformer_block_27[2][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 3000)         0           transformer_block_27[3][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 64)           192064      flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64)           0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 3)            195         dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 213,391\n",
      "Trainable params: 213,391\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer TransformerBlock has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/150\n",
      "796/796 [==============================] - 39s 43ms/step - loss: 1.7701 - sparse_categorical_accuracy: 0.4068 - val_loss: 1.1059 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 2/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 1.0397 - sparse_categorical_accuracy: 0.4120 - val_loss: 1.1049 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 3/150\n",
      "796/796 [==============================] - 29s 36ms/step - loss: 1.0363 - sparse_categorical_accuracy: 0.4154 - val_loss: 1.1080 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 4/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 1.0388 - sparse_categorical_accuracy: 0.4116 - val_loss: 1.1073 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 5/150\n",
      "796/796 [==============================] - 31s 39ms/step - loss: 1.0372 - sparse_categorical_accuracy: 0.4112 - val_loss: 1.1044 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 6/150\n",
      "796/796 [==============================] - 31s 39ms/step - loss: 1.0382 - sparse_categorical_accuracy: 0.4115 - val_loss: 1.1042 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 7/150\n",
      "796/796 [==============================] - 29s 36ms/step - loss: 1.0380 - sparse_categorical_accuracy: 0.4114 - val_loss: 1.1047 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 8/150\n",
      "796/796 [==============================] - 30s 38ms/step - loss: 1.0365 - sparse_categorical_accuracy: 0.4115 - val_loss: 1.1051 - val_sparse_categorical_accuracy: 0.3723\n",
      "Epoch 9/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 1.0380 - sparse_categorical_accuracy: 0.4162 - val_loss: 1.1072 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 10/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 1.0381 - sparse_categorical_accuracy: 0.4112 - val_loss: 1.1050 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 11/150\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 1.0400 - sparse_categorical_accuracy: 0.4115 - val_loss: 1.1074 - val_sparse_categorical_accuracy: 0.3723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54     18931\n",
      "           1       0.00      0.00      0.00     13201\n",
      "           2       0.00      0.00      0.00     18717\n",
      "\n",
      "    accuracy                           0.37     50849\n",
      "   macro avg       0.12      0.33      0.18     50849\n",
      "weighted avg       0.14      0.37      0.20     50849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vslaykovsky/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m[I 2021-07-25 18:00:53,336]\u001b[0m Trial 2 finished with value: 0.17564623096061632 and parameters: {'num_conv_filters': 29, 'max_conv_dilation': 32, 'num_attention_heads': 3, 'num_transformer_blocks': 4, 'transformer_blocks_share_weights': True, 'dropout_rate': 0.13613947801791706, 'learning_rate': 0.0037159445431409004}. Best is trial 0 with value: 0.4340597140988169.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      1.00      0.51     47913\n",
      "           1       0.00      0.00      0.00     48050\n",
      "           2       0.00      0.00      0.00     43523\n",
      "\n",
      "    accuracy                           0.34    139486\n",
      "   macro avg       0.11      0.33      0.17    139486\n",
      "weighted avg       0.12      0.34      0.18    139486\n",
      "\n",
      "Train (203799, 40) (203799,) Val (50949, 40) (50949,)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 100, 40)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 100, 29)      2349        input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 100, 29)      1711        conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 100, 29)      1711        conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 100, 29)      1711        conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 100, 29)      1711        conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 100, 29)      58          conv1d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_layer_17 (P (None, 100, 30)      0           layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_28 (Transform (None, 100, 30)      10170       positional_encoding_layer_17[0][0\n",
      "                                                                 transformer_block_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 3000)         0           transformer_block_28[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 64)           192064      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64)           0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 3)            195         dropout_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 211,680\n",
      "Trainable params: 211,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer TransformerBlock has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/150\n",
      "796/796 [==============================] - 25s 28ms/step - loss: 2.2500 - sparse_categorical_accuracy: 0.4052 - val_loss: 2.0171 - val_sparse_categorical_accuracy: 0.3775\n",
      "Epoch 2/150\n",
      "796/796 [==============================] - 21s 27ms/step - loss: 1.8837 - sparse_categorical_accuracy: 0.4240 - val_loss: 1.7713 - val_sparse_categorical_accuracy: 0.3704\n",
      "Epoch 3/150\n",
      "796/796 [==============================] - 21s 27ms/step - loss: 1.6565 - sparse_categorical_accuracy: 0.4265 - val_loss: 1.5993 - val_sparse_categorical_accuracy: 0.3674\n",
      "Epoch 4/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.4933 - sparse_categorical_accuracy: 0.4308 - val_loss: 1.4779 - val_sparse_categorical_accuracy: 0.3802\n",
      "Epoch 5/150\n",
      "796/796 [==============================] - 22s 27ms/step - loss: 1.3767 - sparse_categorical_accuracy: 0.4390 - val_loss: 1.3999 - val_sparse_categorical_accuracy: 0.3843\n",
      "Epoch 6/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.2973 - sparse_categorical_accuracy: 0.4436 - val_loss: 1.3396 - val_sparse_categorical_accuracy: 0.3758\n",
      "Epoch 7/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 1.2424 - sparse_categorical_accuracy: 0.4482 - val_loss: 1.2956 - val_sparse_categorical_accuracy: 0.3790\n",
      "Epoch 8/150\n",
      "796/796 [==============================] - 21s 27ms/step - loss: 1.1989 - sparse_categorical_accuracy: 0.4553 - val_loss: 1.2656 - val_sparse_categorical_accuracy: 0.3926\n",
      "Epoch 9/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.1652 - sparse_categorical_accuracy: 0.4657 - val_loss: 1.2439 - val_sparse_categorical_accuracy: 0.3960\n",
      "Epoch 10/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 1.1389 - sparse_categorical_accuracy: 0.4724 - val_loss: 1.2243 - val_sparse_categorical_accuracy: 0.4006\n",
      "Epoch 11/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.1185 - sparse_categorical_accuracy: 0.4795 - val_loss: 1.2107 - val_sparse_categorical_accuracy: 0.4041\n",
      "Epoch 12/150\n",
      "796/796 [==============================] - 24s 30ms/step - loss: 1.0966 - sparse_categorical_accuracy: 0.4894 - val_loss: 1.1968 - val_sparse_categorical_accuracy: 0.4017\n",
      "Epoch 13/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 1.0754 - sparse_categorical_accuracy: 0.4988 - val_loss: 1.1877 - val_sparse_categorical_accuracy: 0.4072\n",
      "Epoch 14/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 1.0616 - sparse_categorical_accuracy: 0.5055 - val_loss: 1.1753 - val_sparse_categorical_accuracy: 0.4078\n",
      "Epoch 15/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.0449 - sparse_categorical_accuracy: 0.5128 - val_loss: 1.1644 - val_sparse_categorical_accuracy: 0.4115\n",
      "Epoch 16/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.0334 - sparse_categorical_accuracy: 0.5175 - val_loss: 1.1552 - val_sparse_categorical_accuracy: 0.4142\n",
      "Epoch 17/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.0174 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.1471 - val_sparse_categorical_accuracy: 0.4191\n",
      "Epoch 18/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 1.0070 - sparse_categorical_accuracy: 0.5278 - val_loss: 1.1385 - val_sparse_categorical_accuracy: 0.4227\n",
      "Epoch 19/150\n",
      "796/796 [==============================] - 26s 32ms/step - loss: 0.9969 - sparse_categorical_accuracy: 0.5347 - val_loss: 1.1335 - val_sparse_categorical_accuracy: 0.4200\n",
      "Epoch 20/150\n",
      "796/796 [==============================] - 28s 36ms/step - loss: 0.9843 - sparse_categorical_accuracy: 0.5408 - val_loss: 1.1273 - val_sparse_categorical_accuracy: 0.4253\n",
      "Epoch 21/150\n",
      "796/796 [==============================] - 25s 31ms/step - loss: 0.9748 - sparse_categorical_accuracy: 0.5502 - val_loss: 1.1208 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 22/150\n",
      "796/796 [==============================] - 23s 28ms/step - loss: 0.9630 - sparse_categorical_accuracy: 0.5526 - val_loss: 1.1139 - val_sparse_categorical_accuracy: 0.4301\n",
      "Epoch 23/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.9571 - sparse_categorical_accuracy: 0.5557 - val_loss: 1.1084 - val_sparse_categorical_accuracy: 0.4354\n",
      "Epoch 24/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.9505 - sparse_categorical_accuracy: 0.5573 - val_loss: 1.1047 - val_sparse_categorical_accuracy: 0.4375\n",
      "Epoch 25/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.9401 - sparse_categorical_accuracy: 0.5648 - val_loss: 1.1003 - val_sparse_categorical_accuracy: 0.4392\n",
      "Epoch 26/150\n",
      "796/796 [==============================] - 24s 30ms/step - loss: 0.9360 - sparse_categorical_accuracy: 0.5652 - val_loss: 1.0982 - val_sparse_categorical_accuracy: 0.4404\n",
      "Epoch 27/150\n",
      "796/796 [==============================] - 24s 30ms/step - loss: 0.9248 - sparse_categorical_accuracy: 0.5714 - val_loss: 1.0909 - val_sparse_categorical_accuracy: 0.4434\n",
      "Epoch 28/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.9186 - sparse_categorical_accuracy: 0.5767 - val_loss: 1.0870 - val_sparse_categorical_accuracy: 0.4452\n",
      "Epoch 29/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.9137 - sparse_categorical_accuracy: 0.5793 - val_loss: 1.0914 - val_sparse_categorical_accuracy: 0.4405\n",
      "Epoch 30/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.9060 - sparse_categorical_accuracy: 0.5827 - val_loss: 1.0823 - val_sparse_categorical_accuracy: 0.4470\n",
      "Epoch 31/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.9032 - sparse_categorical_accuracy: 0.5859 - val_loss: 1.0808 - val_sparse_categorical_accuracy: 0.4496\n",
      "Epoch 32/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8963 - sparse_categorical_accuracy: 0.5897 - val_loss: 1.0792 - val_sparse_categorical_accuracy: 0.4453\n",
      "Epoch 33/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8897 - sparse_categorical_accuracy: 0.5953 - val_loss: 1.0778 - val_sparse_categorical_accuracy: 0.4510\n",
      "Epoch 34/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8861 - sparse_categorical_accuracy: 0.5942 - val_loss: 1.0752 - val_sparse_categorical_accuracy: 0.4513\n",
      "Epoch 35/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8819 - sparse_categorical_accuracy: 0.5992 - val_loss: 1.0695 - val_sparse_categorical_accuracy: 0.4575\n",
      "Epoch 36/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8749 - sparse_categorical_accuracy: 0.6024 - val_loss: 1.0689 - val_sparse_categorical_accuracy: 0.4573\n",
      "Epoch 37/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8729 - sparse_categorical_accuracy: 0.6039 - val_loss: 1.0653 - val_sparse_categorical_accuracy: 0.4615\n",
      "Epoch 38/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8717 - sparse_categorical_accuracy: 0.6036 - val_loss: 1.0673 - val_sparse_categorical_accuracy: 0.4562\n",
      "Epoch 39/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8632 - sparse_categorical_accuracy: 0.6096 - val_loss: 1.0731 - val_sparse_categorical_accuracy: 0.4531\n",
      "Epoch 40/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8606 - sparse_categorical_accuracy: 0.6105 - val_loss: 1.0667 - val_sparse_categorical_accuracy: 0.4606\n",
      "Epoch 41/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8565 - sparse_categorical_accuracy: 0.6145 - val_loss: 1.0621 - val_sparse_categorical_accuracy: 0.4629\n",
      "Epoch 42/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8506 - sparse_categorical_accuracy: 0.6185 - val_loss: 1.0632 - val_sparse_categorical_accuracy: 0.4624\n",
      "Epoch 43/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8509 - sparse_categorical_accuracy: 0.6200 - val_loss: 1.0638 - val_sparse_categorical_accuracy: 0.4637\n",
      "Epoch 44/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8485 - sparse_categorical_accuracy: 0.6202 - val_loss: 1.0628 - val_sparse_categorical_accuracy: 0.4652\n",
      "Epoch 45/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8446 - sparse_categorical_accuracy: 0.6222 - val_loss: 1.0589 - val_sparse_categorical_accuracy: 0.4686\n",
      "Epoch 46/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8426 - sparse_categorical_accuracy: 0.6227 - val_loss: 1.0630 - val_sparse_categorical_accuracy: 0.4677\n",
      "Epoch 47/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8335 - sparse_categorical_accuracy: 0.6272 - val_loss: 1.0653 - val_sparse_categorical_accuracy: 0.4659\n",
      "Epoch 48/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8354 - sparse_categorical_accuracy: 0.6278 - val_loss: 1.0618 - val_sparse_categorical_accuracy: 0.4680\n",
      "Epoch 49/150\n",
      "796/796 [==============================] - 23s 28ms/step - loss: 0.8332 - sparse_categorical_accuracy: 0.6299 - val_loss: 1.0570 - val_sparse_categorical_accuracy: 0.4725\n",
      "Epoch 50/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8269 - sparse_categorical_accuracy: 0.6312 - val_loss: 1.0665 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 51/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8268 - sparse_categorical_accuracy: 0.6344 - val_loss: 1.0573 - val_sparse_categorical_accuracy: 0.4707\n",
      "Epoch 52/150\n",
      "796/796 [==============================] - 23s 28ms/step - loss: 0.8232 - sparse_categorical_accuracy: 0.6354 - val_loss: 1.0600 - val_sparse_categorical_accuracy: 0.4694\n",
      "Epoch 53/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8170 - sparse_categorical_accuracy: 0.6380 - val_loss: 1.0612 - val_sparse_categorical_accuracy: 0.4697\n",
      "Epoch 54/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8174 - sparse_categorical_accuracy: 0.6398 - val_loss: 1.0614 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 55/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8141 - sparse_categorical_accuracy: 0.6412 - val_loss: 1.0628 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 56/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8144 - sparse_categorical_accuracy: 0.6423 - val_loss: 1.0603 - val_sparse_categorical_accuracy: 0.4725\n",
      "Epoch 57/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8073 - sparse_categorical_accuracy: 0.6469 - val_loss: 1.0627 - val_sparse_categorical_accuracy: 0.4731\n",
      "Epoch 58/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8065 - sparse_categorical_accuracy: 0.6459 - val_loss: 1.0638 - val_sparse_categorical_accuracy: 0.4716\n",
      "Epoch 59/150\n",
      "796/796 [==============================] - 22s 28ms/step - loss: 0.8027 - sparse_categorical_accuracy: 0.6490 - val_loss: 1.0651 - val_sparse_categorical_accuracy: 0.4718\n",
      "Epoch 60/150\n",
      "796/796 [==============================] - 23s 28ms/step - loss: 0.8003 - sparse_categorical_accuracy: 0.6510 - val_loss: 1.0621 - val_sparse_categorical_accuracy: 0.4721\n",
      "Epoch 61/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.8016 - sparse_categorical_accuracy: 0.6502 - val_loss: 1.0626 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 62/150\n",
      "796/796 [==============================] - 24s 30ms/step - loss: 0.7957 - sparse_categorical_accuracy: 0.6542 - val_loss: 1.0670 - val_sparse_categorical_accuracy: 0.4722\n",
      "Epoch 63/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.7917 - sparse_categorical_accuracy: 0.6575 - val_loss: 1.0641 - val_sparse_categorical_accuracy: 0.4758\n",
      "Epoch 64/150\n",
      "796/796 [==============================] - 24s 30ms/step - loss: 0.7904 - sparse_categorical_accuracy: 0.6579 - val_loss: 1.0656 - val_sparse_categorical_accuracy: 0.4749\n",
      "Epoch 65/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.7894 - sparse_categorical_accuracy: 0.6587 - val_loss: 1.0676 - val_sparse_categorical_accuracy: 0.4722\n",
      "Epoch 66/150\n",
      "796/796 [==============================] - 23s 29ms/step - loss: 0.7822 - sparse_categorical_accuracy: 0.6617 - val_loss: 1.0741 - val_sparse_categorical_accuracy: 0.4701\n",
      "Epoch 67/150\n",
      "796/796 [==============================] - 24s 30ms/step - loss: 0.7831 - sparse_categorical_accuracy: 0.6636 - val_loss: 1.0656 - val_sparse_categorical_accuracy: 0.4752\n",
      "Epoch 68/150\n",
      "295/796 [==========>...................] - ETA: 13s - loss: 0.7809 - sparse_categorical_accuracy: 0.6631"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-653c7ba1732c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptuna_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-653c7ba1732c>\u001b[0m in \u001b[0;36moptuna_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     }\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-653c7ba1732c>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_translob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-59b856a7def3>\u001b[0m in \u001b[0;36mtrain_translob\u001b[0;34m(X_train, y_train, X_val, y_val, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mval_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeseriesGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1161\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def test_model(params):\n",
    "    model = train_translob(X_train, y_train, X_val, y_val, **params)\n",
    "    eval(model, X_val, y_val, **params)\n",
    "    return eval(model, X_test, y_test, **params)\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    params = {\n",
    "        # inputs\n",
    "        'sequence_length': 100,\n",
    "        # model\n",
    "        'num_conv_filters': trial.suggest_categorical('num_conv_filters', [14, 29]),\n",
    "        'max_conv_dilation': trial.suggest_categorical('max_conv_dilation', [16, 32]),\n",
    "        'num_attention_heads': trial.suggest_categorical('num_attention_heads', [3, 5]),\n",
    "        'num_transformer_blocks': trial.suggest_categorical('num_transformer_blocks', [2, 3, 4]),\n",
    "        'transformer_blocks_share_weights': trial.suggest_categorical('transformer_blocks_share_weights', [True, False]),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.0, 0.3),\n",
    "        # training\n",
    "        'lr': trial.suggest_float('learning_rate', 0.00001, 0.01, log=True),\n",
    "        'adam_beta1': 0.9,\n",
    "        'adam_beta2': 0.999,\n",
    "        # 'batch_size': 32,\n",
    "        #'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'batch_size': 256,\n",
    "        'epochs': 150\n",
    "    }\n",
    "    return test_model(params)\n",
    "   \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optuna_objective, n_trials=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('translob_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a9191c6b2d33302590e376f8aee71d3c7e87a446da0bda5474eb7c47655c891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
