{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras import Model\n",
    "from keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "import modules.blocks as blocks\n",
    "import modules.data as data\n",
    "from modules.utilites import DataClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parametrs\n",
    "class Input_pars(DataClass):\n",
    "    seq_len = 100\n",
    "\n",
    "\n",
    "class CN_pars(DataClass):\n",
    "    n_filters = 14\n",
    "    dilation_steps = 4  # dilation = 2**dilation_step\n",
    "\n",
    "\n",
    "class AN_pars(DataClass):\n",
    "    attention_heads = 3\n",
    "    blocks = 2\n",
    "    share_weights = True\n",
    "\n",
    "\n",
    "class FF_pars(DataClass):\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "\n",
    "class Optimaser_pars(DataClass):\n",
    "    lr = 0.0001\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "\n",
    "\n",
    "class Trainig_pars(DataClass):\n",
    "    shuffle = True\n",
    "    batch_size = 512\n",
    "    epochs = 150\n",
    "\n",
    "\n",
    "class Full_pars(DataClass):\n",
    "    seq_len = 100\n",
    "    cn = CN_pars()\n",
    "    an = AN_pars()\n",
    "    ff = FF_pars()\n",
    "    optimazer = Optimaser_pars()\n",
    "    training = Trainig_pars()\n",
    "\n",
    "\n",
    "pars = Full_pars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test,y_test) = data.load_dataset(horizon=4) # yapf:disabele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = data.build_dataset(\n",
    "    \n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    seq_len=pars.seq_len,\n",
    ")\n",
    "\n",
    "ds_val = data.build_dataset(\n",
    "    x=x_val,\n",
    "    y=y_val,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    seq_len=pars.seq_len,\n",
    ")\n",
    "\n",
    "ds_test = data.build_dataset(\n",
    "    x=x_test,\n",
    "    y=y_test,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    seq_len=pars.seq_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"private__transformer_block\" (type _TransformerBlock).\n\nin user code:\n\n    File \"d:\\WORKS\\translob\\LOB\\modules\\blocks.py\", line 384, in call  *\n        output = self.attention_layer(x)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\WORKS\\translob\\LOB\\modules\\blocks.py\", line 102, in build\n        self.validate_model_dimensionality(d_model)\n    File \"d:\\WORKS\\translob\\LOB\\modules\\blocks.py\", line 147, in validate_model_dimensionality\n        raise ValueError(\n\n    ValueError: The size of the last dimension of the input (40) must be evenly divisible by the numberof the attention heads 3\n\n\nCall arguments received by layer \"private__transformer_block\" (type _TransformerBlock):\n  • x=tf.Tensor(shape=(None, 100, 40), dtype=float32)\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m inputs \u001b[39m=\u001b[39m blocks\u001b[39m.\u001b[39minput_block(pars\u001b[39m.\u001b[39mseq_len)\n\u001b[0;32m      3\u001b[0m \u001b[39m# cnn = blocks.cnn_block(\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#     input_layer=inputs,\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m#     filters=pars.cn.n_filters,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# norm = blocks.norm_block(input_layer=cnn)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# pos = blocks.positional_encoder_block(input_layer=norm)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m transformer \u001b[39m=\u001b[39m blocks\u001b[39m.\u001b[39;49mtransformer_block(\n\u001b[0;32m     11\u001b[0m     input_layer\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m     12\u001b[0m     n_blocks\u001b[39m=\u001b[39;49mpars\u001b[39m.\u001b[39;49man\u001b[39m.\u001b[39;49mblocks,\n\u001b[0;32m     13\u001b[0m     n_heads\u001b[39m=\u001b[39;49mpars\u001b[39m.\u001b[39;49man\u001b[39m.\u001b[39;49mattention_heads,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m ffn \u001b[39m=\u001b[39m blocks\u001b[39m.\u001b[39mffn_block(\n\u001b[0;32m     16\u001b[0m     input_layer\u001b[39m=\u001b[39mtransformer,\n\u001b[0;32m     17\u001b[0m     dropout_rate\u001b[39m=\u001b[39mpars\u001b[39m.\u001b[39mff\u001b[39m.\u001b[39mdropout_rate,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39minputs, outputs\u001b[39m=\u001b[39mffn)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\LOB\\modules\\blocks.py:395\u001b[0m, in \u001b[0;36mtransformer_block\u001b[1;34m(input_layer, n_blocks, n_heads)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransformer_block\u001b[39m(input_layer, n_blocks, n_heads):\n\u001b[0;32m    394\u001b[0m     \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_blocks):\n\u001b[1;32m--> 395\u001b[0m         input_layer \u001b[39m=\u001b[39m _TransformerBlock(\n\u001b[0;32m    396\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtransformer_block_\u001b[39;49m\u001b[39m{\u001b[39;49;00mblock\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    397\u001b[0m             n_heads,\n\u001b[0;32m    398\u001b[0m             \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    399\u001b[0m         )(input_layer)\n\u001b[0;32m    400\u001b[0m     \u001b[39mreturn\u001b[39;00m input_layer\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file7clz0iox.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mattention_layer, (ag__\u001b[39m.\u001b[39;49mld(x),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     11\u001b[0m post_residual1 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39maddition_layer, ([ag__\u001b[39m.\u001b[39mld(x), ag__\u001b[39m.\u001b[39mld(output)],), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m norm1_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mnorm1_layer, (ag__\u001b[39m.\u001b[39mld(post_residual1),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\LOB\\modules\\blocks.py:102\u001b[0m, in \u001b[0;36m_MultiHeadSelfAttention.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, input_shape):\n\u001b[0;32m     98\u001b[0m     \u001b[39m# if not isinstance(input_shape, TensorShape):\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[39m#     raise ValueError('Invalid input')\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     d_model \u001b[39m=\u001b[39m input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_model_dimensionality(d_model)\n\u001b[0;32m    103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqkv_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_weight(\n\u001b[0;32m    104\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mqkv_weights\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    105\u001b[0m         shape\u001b[39m=\u001b[39m(d_model, d_model \u001b[39m*\u001b[39m \u001b[39m3\u001b[39m),  \u001b[39m# * 3 for q, k and v\u001b[39;00m\n\u001b[0;32m    106\u001b[0m         initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mglorot_uniform\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    107\u001b[0m         trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m     )\n\u001b[0;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mbuild(input_shape)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\LOB\\modules\\blocks.py:147\u001b[0m, in \u001b[0;36m_MultiHeadSelfAttention.validate_model_dimensionality\u001b[1;34m(self, d_model)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_model_dimensionality\u001b[39m(\u001b[39mself\u001b[39m, d_model: \u001b[39mint\u001b[39m):\n\u001b[0;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m d_model \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 147\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    148\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe size of the last dimension of the input \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    149\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00md_model\u001b[39m}\u001b[39;00m\u001b[39m) must be evenly divisible by the number\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    150\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mof the attention heads \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"private__transformer_block\" (type _TransformerBlock).\n\nin user code:\n\n    File \"d:\\WORKS\\translob\\LOB\\modules\\blocks.py\", line 384, in call  *\n        output = self.attention_layer(x)\n    File \"d:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\WORKS\\translob\\LOB\\modules\\blocks.py\", line 102, in build\n        self.validate_model_dimensionality(d_model)\n    File \"d:\\WORKS\\translob\\LOB\\modules\\blocks.py\", line 147, in validate_model_dimensionality\n        raise ValueError(\n\n    ValueError: The size of the last dimension of the input (40) must be evenly divisible by the numberof the attention heads 3\n\n\nCall arguments received by layer \"private__transformer_block\" (type _TransformerBlock):\n  • x=tf.Tensor(shape=(None, 100, 40), dtype=float32)\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "inputs = blocks.input_block(pars.seq_len)\n",
    "# cnn = blocks.cnn_block(\n",
    "#     input_layer=inputs,\n",
    "#     filters=pars.cn.n_filters,\n",
    "#     dilation_steps=pars.cn.dilation_steps,\n",
    "# )\n",
    "# norm = blocks.norm_block(input_layer=cnn)\n",
    "# pos = blocks.positional_encoder_block(input_layer=norm)\n",
    "transformer = blocks.transformer_block(\n",
    "    input_layer=inputs,\n",
    "    n_blocks=pars.an.blocks,\n",
    "    n_heads=pars.an.attention_heads,\n",
    ")\n",
    "ffn = blocks.ffn_block(\n",
    "    input_layer=transformer,\n",
    "    dropout_rate=pars.ff.dropout_rate,\n",
    ")\n",
    "model = Model(inputs=inputs, outputs=ffn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 40)]         0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 100, 14)           1134      \n",
      "                                                                 \n",
      " layer_normalization_2 (Lay  (None, 100, 14)           28        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " private__positional_encodi  (None, 100, 15)           0         \n",
      " ng_layer_2 (_PositionalEnc                                      \n",
      " odingLayer)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1162 (4.54 KB)\n",
      "Trainable params: 1162 (4.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Train x: (203799, 40)    - y: (203799,)\n",
      "Val   x: (50949, 40)     - y: (50949,)\n"
     ]
    }
   ],
   "source": [
    "# CompiLe\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.Adam(\n",
    "        learning_rate=pars.optimazer.lr,\n",
    "        beta_1=pars.optimazer.adam_beta1,\n",
    "        beta_2=pars.optimazer.adam_beta2,\n",
    "        name=\"Adam\",\n",
    "    ),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "print(\n",
    "    f'Train x: {str(x_train.shape): <15} - y: {y_train.shape}',\n",
    "    f'Val   x: {str(x_val.shape): <15} - y: {y_val.shape}',\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=pars.training.epochs,\n",
    "    validation_data=ds_val,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('translob_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a9191c6b2d33302590e376f8aee71d3c7e87a446da0bda5474eb7c47655c891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
