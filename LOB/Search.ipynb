{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For collab\n",
    "%tensorboard\n",
    "# try:\n",
    "#     from google.colab import drive\n",
    "#     drive.mount('/content/drive/',force_remount=True)\n",
    "#     %cd /content/drive/My Drive/LOB/\n",
    "#     %pip install automodinit keras_tuner\n",
    "#     !nohup /usr/bin/python3 /content/drive/MyDrive/LOB/Colab_saver.py &\n",
    "# except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "\n",
    "from tools import utils, express\n",
    "from tools.utils import DataClass\n",
    "from models import m_base as test_model\n",
    "\n",
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "proportion = input('Data proportion 100-0 in % (press enter for all): ')\n",
    "if proportion == '': proportion = 1\n",
    "else: proportion = float(proportion) / 100\n",
    "\n",
    "row_data = express.load_saved_datas(proportion)\n",
    "# row_data = data.load_datas(horizon,path=r'../dataset/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore',)\n",
    "express.inspect_datas(row_data)\n",
    "\n",
    "datasets = express.build_datasets(\n",
    "    datas=row_data,\n",
    "    batch_size=100,\n",
    "    seq_len=seq_len,\n",
    ")\n",
    "(ds_train, ds_val, ds_test) =\\\n",
    "(datasets['train'], datasets['val'], datasets['test'])\n",
    "express.inspect_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataClass(test_model.PARAMETRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuner parametrs\n",
    "# def configure(hp: keras_tuner.HyperParameters):\n",
    "\n",
    "#     class CN_search(DataClass):\n",
    "#         dilation_steps = hp.Int(\n",
    "#             'dilation_steps',\n",
    "#             default=4,\n",
    "#             min_value=3,\n",
    "#             max_value=5,\n",
    "#             step=1,\n",
    "#         )\n",
    "\n",
    "#     class AN_search(DataClass):\n",
    "#         share_weights = hp.Boolean(\n",
    "#             'share_weights',\n",
    "#             default=True,\n",
    "#         )\n",
    "#         blocks = hp.Int(\n",
    "#             'an_blocks',\n",
    "#             default=2,\n",
    "#             min_value=1,\n",
    "#             max_value=3,\n",
    "#             step=1,\n",
    "#         )\n",
    "\n",
    "#     class Full_search(DataClass):\n",
    "#         cn = CN_search()\n",
    "#         an = AN_search()\n",
    "\n",
    "#     return Full_search()\n",
    "\n",
    "\n",
    "def configure(hp: keras_tuner.HyperParameters):\n",
    "\n",
    "    class convolutional_search(DataClass):\n",
    "        dilation_steps = 5\n",
    "\n",
    "    class transformer_search(DataClass):\n",
    "        share_weights = hp.Boolean(\n",
    "            'share_weights',\n",
    "            default=True,\n",
    "        )\n",
    "\n",
    "    class feed_forward_search(DataClass):\n",
    "        activation = hp.Choice(name='activation',\n",
    "                               values=['relu', 'None'],\n",
    "                               default='relu')\n",
    "        kernel_regularizer = hp.Choice(\n",
    "            name='regularizer',\n",
    "            values=['l2', 'None'],\n",
    "            default='l2',\n",
    "        )\n",
    "\n",
    "    class Full_search(DataClass):\n",
    "        convolutional = convolutional_search()\n",
    "        transformer = transformer_search()\n",
    "        feed_forward = feed_forward_search()\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "            learning_rate=hp.Choice(\n",
    "                name='lr',\n",
    "                default=0.0001,\n",
    "                values=[0.01, 0.001, 0.0005, 0.0001],\n",
    "            ),\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "        )\n",
    "\n",
    "    return Full_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build\n",
    "def search_model(hp):\n",
    "    hyper_pars_data = configure(hp)\n",
    "\n",
    "    default_parametrs = DataClass(test_model.PARAMETRS)\n",
    "    parametrs = default_parametrs.Info_expanded\n",
    "    parametrs.update(hyper_pars_data.Info_expanded)\n",
    "\n",
    "    model = test_model.build_model(**parametrs)\n",
    "    return model\n",
    "\n",
    "\n",
    "input_name = ''\n",
    "date_tag = f'({datetime.datetime.now().strftime(\"%H-%M-%S--%d.%m\")})'\n",
    "while input_name == '':\n",
    "    input_name = input(f\"Input search name: \")\n",
    "search_name = f'search_{input_name}{date_tag}'\n",
    "\n",
    "print(\n",
    "    f'Pattern model: {test_model.__name__}',\n",
    "    f'Search name: {search_name}',\n",
    "    'Parametrs:',\n",
    "    DataClass(test_model.PARAMETRS),\n",
    "    'Changed parametrs:',\n",
    "    configure(keras_tuner.HyperParameters()),\n",
    "    sep='\\n',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Callbacks\n",
    "callback_freq = 100\n",
    "model_dir = f'{express.callback_path}/{search_name}'\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=model_dir,\n",
    "        histogram_freq=callback_freq,\n",
    "        update_freq=callback_freq,\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Callbacks:\\n{[str(type(callback)).split('.')[-1] for callback in callbacks]}\",\n",
    "    f'Directory: {model_dir}',\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build tuner\n",
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=search_model,\n",
    "    objective=\"loss\",\n",
    "    executions_per_trial=1,\n",
    "    directory=model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train\n",
    "training_question = ''\n",
    "while training_question not in ['y', 'n']:\n",
    "    training_question = input('Start training now? (y-yes) (n-exit): ')\n",
    "if training_question == 'y':\n",
    "    tuner.search(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=20,\n",
    "        callbacks=callbacks,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zGPU_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15c3c8882de147eda8616aa412d6cb2a921cdd19c8088b1f5bdfa95af6065bbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
