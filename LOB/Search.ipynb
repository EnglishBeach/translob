{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import timeseries_dataset_from_array\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import modules.data as data\n",
    "from modules.utilites import DataClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parametrs\n",
    "class Input_pars(DataClass):\n",
    "    seq_len = 100\n",
    "\n",
    "\n",
    "class CN_pars(DataClass):\n",
    "    n_filters = 14\n",
    "    dilation_steps = 4  # dilation = 2**dilation_step\n",
    "\n",
    "\n",
    "class AN_pars(DataClass):\n",
    "    attention_heads = 3\n",
    "    blocks = 2\n",
    "    share_weights = False\n",
    "\n",
    "\n",
    "class FF_pars(DataClass):\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "\n",
    "class Optimaser_pars(DataClass):\n",
    "    lr = 0.0001\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "\n",
    "\n",
    "class Trainig_pars(DataClass):\n",
    "    shuffle = True\n",
    "    batch_size = 512\n",
    "    epochs = 150\n",
    "\n",
    "\n",
    "class Full_pars(DataClass):\n",
    "    seq_len = 100\n",
    "    cn = CN_pars()\n",
    "    an = AN_pars()\n",
    "    ff = FF_pars()\n",
    "    optimazer = Optimaser_pars()\n",
    "    training = Trainig_pars()\n",
    "\n",
    "\n",
    "pars = Full_pars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i= keras.Input(shape=(20,20))\n",
    "# x= keras.layers.Reshape((20,20,1))(i)\n",
    "\n",
    "# x= keras.layers.Conv2D(\n",
    "#     kernel_size=(1,2),\n",
    "#     filters=9,\n",
    "#     padding='same',\n",
    "#     # input_shape=(None, 20, 20),\n",
    "# )(x)\n",
    "\n",
    "# model = keras.Model(inputs=i, outputs=x)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model\n",
    "# inputs = blocks.input_block(pars.seq_len)\n",
    "# x= inputs\n",
    "\n",
    "\n",
    "# x = blocks.cnn_block(\n",
    "#     input_layer=x,\n",
    "#     filters=pars.cn.n_filters,\n",
    "#     dilation_steps=pars.cn.dilation_steps,\n",
    "# )\n",
    "\n",
    "# # x= keras.layers.Reshape(target_shape=(100,14,1))(x)\n",
    "# # x = LobFeatures.lob_inception(x)\n",
    "# # x= LobFeatures.lob_cnn(x)\n",
    "\n",
    "\n",
    "# x = blocks.norm_block(input_layer=x)\n",
    "\n",
    "# x = blocks.positional_encoder_block(input_layer=x)\n",
    "\n",
    "\n",
    "# x = blocks.transformer_block(\n",
    "#     input_layer=x,\n",
    "#     n_blocks=pars.an.blocks,\n",
    "#     n_heads=pars.an.attention_heads,\n",
    "#     share_weights=pars.an.share_weights,\n",
    "# )\n",
    "\n",
    "\n",
    "# x = blocks.ffn_block(\n",
    "#     input_layer=x,\n",
    "#     dropout_rate=pars.ff.dropout_rate,\n",
    "# )\n",
    "\n",
    "\n",
    "# model = keras.Model(inputs=inputs, outputs=x)\n",
    "# model.summary(\n",
    "#     line_length=100,\n",
    "#     expand_nested=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x_train, y_train), (x_val, y_val), (x_test, y_test)) =(\n",
    "# data.load_dataset(horizon=4)\n",
    "data.load_saved_data()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.save_data(name= 'train',x= x_train,y=y_train)\n",
    "# data.save_data(name= 'val',x= x_val,y=y_val)\n",
    "# data.save_data(name= 'test',x= x_test,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x: (203799, 40)    - y: (203799,)       - tensor: 398 - [None, 100, 40]\n",
      "Val   x: (50949, 40)     - y: (50949,)        - tensor: 100 - [None, 100, 40]\n",
      "Test  x: (139586, 40)    - y: (139586,)       - tensor: 273 - [None, 100, 40]\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "ds_train = data.build_dataset(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    seq_len=pars.seq_len,\n",
    ")\n",
    "\n",
    "ds_val = data.build_dataset(\n",
    "    x=x_val,\n",
    "    y=y_val,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    seq_len=pars.seq_len,\n",
    ")\n",
    "\n",
    "ds_test = data.build_dataset(\n",
    "    x=x_test,\n",
    "    y=y_test,\n",
    "    batch_size=pars.training.batch_size,\n",
    "    seq_len=pars.seq_len,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'Train x: {str(x_train.shape): <15} - y: {str(y_train.shape): <15}'+\\\n",
    "    f' - tensor: {len(ds_train)} - {list(ds_train.element_spec[0].shape)}',\n",
    "    f'Val   x: {str(x_val.shape): <15} - y: {str(y_val.shape): <15}'+\\\n",
    "    f' - tensor: {len(ds_val)} - {list(ds_val.element_spec[0].shape)}',\n",
    "    f'Test  x: {str(x_test.shape): <15} - y: {str(y_test.shape): <15}'+\\\n",
    "    f' - tensor: {len(ds_test)} - {list(ds_test.element_spec[0].shape)}',\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import base_model,model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CompiLe\n",
    "# model.compile(\n",
    "#     keras.optimizers.Adam(\n",
    "#         learning_rate=pars.optimazer.lr,\n",
    "#         beta_1=pars.optimazer.adam_beta1,\n",
    "#         beta_2=pars.optimazer.adam_beta2,\n",
    "#         name=\"Adam\",\n",
    "#     ),\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "#     metrics=[\n",
    "#         keras.metrics.CategoricalAccuracy(name='accurancy'),\n",
    "#         keras.metrics.SparseCategoricalAccuracy(name='sparce_accurancy'),\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam= keras.optimizers.Adam(\n",
    "        learning_rate=0.1,\n",
    "        beta_1=0.99,\n",
    "        beta_2=0.9,\n",
    "        name=\"Adam\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_len': 100,\n",
       " 'cn__n_filters': 14,\n",
       " 'cn__dilation_steps': 4,\n",
       " 'an__attention_heads': 3,\n",
       " 'an__blocks': 2,\n",
       " 'an__share_weights': False,\n",
       " 'ff__dropout_rate': 0.1,\n",
       " 'optimazer__lr': 0.0001,\n",
       " 'optimazer__adam_beta1': 0.9,\n",
       " 'optimazer__adam_beta2': 0.999,\n",
       " 'training__shuffle': True,\n",
       " 'training__batch_size': 512,\n",
       " 'training__epochs': 150}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars.Info_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'space'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gs \u001b[39m=\u001b[39m GridSearch(\n\u001b[0;32m      2\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      3\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49m{\n\u001b[0;32m      4\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mseq_len\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m100\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mcn__n_filters\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m14\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mcn__dilation_steps\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m4\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39man__attention_heads\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m3\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39man__blocks\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m2\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39man__share_weights\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     10\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mff__dropout_rate\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0.1\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m     },\n\u001b[0;32m     12\u001b[0m     \n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras_tuner\\tuners\\gridsearch.py:420\u001b[0m, in \u001b[0;36mGridSearch.__init__\u001b[1;34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed \u001b[39m=\u001b[39m seed\n\u001b[0;32m    410\u001b[0m oracle \u001b[39m=\u001b[39m GridSearchOracle(\n\u001b[0;32m    411\u001b[0m     objective\u001b[39m=\u001b[39mobjective,\n\u001b[0;32m    412\u001b[0m     max_trials\u001b[39m=\u001b[39mmax_trials,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m     max_consecutive_failed_trials\u001b[39m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[0;32m    419\u001b[0m )\n\u001b[1;32m--> 420\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(oracle, hypermodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras_tuner\\engine\\tuner.py:113\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[1;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[0;32m    106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m     )\n\u001b[1;32m--> 113\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    114\u001b[0m     oracle\u001b[39m=\u001b[39;49moracle,\n\u001b[0;32m    115\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mhypermodel,\n\u001b[0;32m    116\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[0;32m    117\u001b[0m     project_name\u001b[39m=\u001b[39;49mproject_name,\n\u001b[0;32m    118\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[0;32m    119\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[0;32m    120\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    121\u001b[0m )\n\u001b[0;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[0;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:133\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[1;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreload()\n\u001b[0;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     \u001b[39m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_populate_initial_space()\n\u001b[0;32m    135\u001b[0m \u001b[39m# Run in distributed mode.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m dist_utils\u001b[39m.\u001b[39mis_chief_oracle():\n\u001b[0;32m    137\u001b[0m     \u001b[39m# Blocks forever.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[39m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:203\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m hp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_space()\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[1;32m--> 203\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mupdate_space(hp)\n\u001b[0;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activate_all_conditions()\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras_tuner\\engine\\oracle.py:479\u001b[0m, in \u001b[0;36mOracle.update_space\u001b[1;34m(self, hyperparameters)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_space\u001b[39m(\u001b[39mself\u001b[39m, hyperparameters):\n\u001b[0;32m    472\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Add new hyperparameters to the tracking space.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m \u001b[39m    Already recorded parameters get ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39m        hyperparameters: An updated `HyperParameters` object.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     hps \u001b[39m=\u001b[39m hyperparameters\u001b[39m.\u001b[39;49mspace\n\u001b[0;32m    480\u001b[0m     new_hps \u001b[39m=\u001b[39m [\n\u001b[0;32m    481\u001b[0m         hp\n\u001b[0;32m    482\u001b[0m         \u001b[39mfor\u001b[39;00m hp \u001b[39min\u001b[39;00m hps\n\u001b[0;32m    483\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameters\u001b[39m.\u001b[39m_exists(hp\u001b[39m.\u001b[39mname, hp\u001b[39m.\u001b[39mconditions)\n\u001b[0;32m    484\u001b[0m     ]\n\u001b[0;32m    486\u001b[0m     \u001b[39mif\u001b[39;00m new_hps \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_new_entries:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'space'"
     ]
    }
   ],
   "source": [
    "gs = GridSearch(\n",
    "    hypermodel=model,\n",
    "    hyperparameters={\n",
    "        'seq_len': 100,\n",
    "        'cn__n_filters': 14,\n",
    "        'cn__dilation_steps': 4,\n",
    "        'an__attention_heads': 3,\n",
    "        'an__blocks': 2,\n",
    "        'an__share_weights': False,\n",
    "        'ff__dropout_rate': 0.1,\n",
    "    },\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  9/398 [..............................] - ETA: 6:27 - loss: 2.6096 - accurancy: 0.5788 - sparce_accurancy: 0.4206"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      3\u001b[0m     ds_train,\n\u001b[0;32m      4\u001b[0m     \u001b[39m# epochs=pars.training.epochs,\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     validation_data\u001b[39m=\u001b[39;49mds_val,\n\u001b[0;32m      7\u001b[0m     \u001b[39m# callbacks=[\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39m#     CSVLogger(r'logs/model1/log.csv', append=True, separator=';')\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39m# ]\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m )\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    # epochs=pars.training.epochs,\n",
    "    epochs=10,\n",
    "    validation_data=ds_val,\n",
    "    # callbacks=[\n",
    "    #     CSVLogger(r'logs/model1/log.csv', append=True, separator=';')\n",
    "    # ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('translob_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a9191c6b2d33302590e376f8aee71d3c7e87a446da0bda5474eb7c47655c891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
