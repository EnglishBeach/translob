{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from fi2010 import fetch_fi2010\n",
    "import LobAttention, LobFeatures, LobPosition, LobTransformer\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_fi2010()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    1, 2615, 2618, 2619, 2620, 2621, 2623, 2625, 2626, 2629,\n",
       "       2633, 2606, 2604, 2602, 2600, 2599, 2595, 2593, 2591, 2588, 2579,\n",
       "        353,  200,  164,  532,  151,  837,  150,  787,  146,  311,  326,\n",
       "        682,  786,  893,  159,  100,  143,  134,  123,  128,    0,    0,\n",
       "          0,    0,    0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df[(df['DAY']==1)&(df['STOCK']==1)].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = [ i for i in df.columns if 'PRICE' in i]\n",
    "volume = [ i for i in df.columns if 'VOLUME' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_cols = list(sum(zip(price,volume),()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2615,  353, 2618,  200, 2619,  164, 2620,  532, 2621,  151, 2623,\n",
       "        837, 2625,  150, 2626,  787, 2629,  146, 2633,  311, 2606,  326,\n",
       "       2604,  682, 2602,  786, 2600,  893, 2599,  159, 2595,  100, 2593,\n",
       "        143, 2591,  134, 2588,  123, 2579,  128], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df[need_cols].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_simple_data(\n",
    "    df: pd.DataFrame,\n",
    "    group_by=['STOCK', 'DAY'],\n",
    "    last_n=100,\n",
    "):\n",
    "\n",
    "    columns_price = [i for i in df.columns if 'PRICE' in i]\n",
    "    columns_volume = [i for i in df.columns if 'VOLUME' in i]\n",
    "    columns =\\\n",
    "        columns_price[:10] +\\\n",
    "        columns_volume[:10] +\\\n",
    "        columns_price[10:] +\\\n",
    "        columns_volume[10:]\n",
    "\n",
    "    result = np.array(\n",
    "        [i[columns].to_numpy()[-last_n:] for _, i in df.groupby(by=group_by)])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_sequence_tensor(df_stock:pd.DataFrame):\n",
    "#     columns_volume = [i for i in df_stock.columns if 'VOLUME' in i]\n",
    "#     columns_volume = columns_volume[-11::-1] + columns_volume[10:]\n",
    "#     columns_price = [i for i in df_stock.columns if 'PRICE' in i]\n",
    "#     columns_price = columns_price[-11::-1] + columns_price[10:]\n",
    "#     df_price = (\n",
    "#         df_stock[columns_price]\n",
    "#         .stack()\n",
    "#         .to_frame(name='price')\n",
    "#         .reset_index(level=[1])\n",
    "#         .drop(columns='level_1')) # yapf: disable\n",
    "\n",
    "#     df_volume = (\n",
    "#         df_stock[columns_volume]\n",
    "#         .stack()\n",
    "#         .to_frame(name='volume')\n",
    "#         .reset_index(level=[1])\n",
    "#         .drop(columns='level_1'))# yapf: disable\n",
    "    \n",
    "#     book = df_price\n",
    "#     book['volume'] = df_volume\n",
    "#     data = book.to_numpy().reshape(-1, 20, 2)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_simple_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = keras.Input(shape=(100,40),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob_dilated = LobFeatures.lob_dilated(inp)\n",
    "norm = LobTransformer.LayerNormalization()(lob_dilated)\n",
    "encoder = LobPosition.positional_encoding(norm)\n",
    "trans1 =LobTransformer.TransformerBlock(name='1',num_heads=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (100, 15) and (100, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trans1(encoder)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\python\\LobTransformer.py:150\u001b[0m, in \u001b[0;36mTransformerBlock.__call__\u001b[1;34m(self, _input)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, _input):\n\u001b[0;32m    148\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_layer(_input)\n\u001b[0;32m    149\u001b[0m     post_residual1 \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 150\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maddition_layer([_input, output]))\n\u001b[0;32m    151\u001b[0m     norm1_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1_layer(post_residual1)\n\u001b[0;32m    152\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_layer(norm1_output)\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\WORKS\\translob\\translob_env\\Lib\\site-packages\\keras\\src\\layers\\merging\\base_merge.py:74\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[1;34m(self, shape1, shape2)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m j:\n\u001b[1;32m---> 74\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     75\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mInputs have incompatible shapes. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived shapes \u001b[39m\u001b[39m{\u001b[39;00mshape1\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mshape2\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         output_shape\u001b[39m.\u001b[39mappend(i)\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(output_shape)\n",
      "\u001b[1;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (100, 15) and (100, 5)"
     ]
    }
   ],
   "source": [
    "trans1(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(5, 100, 15) dtype=float32 (created by layer 'tf.concat_1')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 ('translob_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a9191c6b2d33302590e376f8aee71d3c7e87a446da0bda5474eb7c47655c891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
