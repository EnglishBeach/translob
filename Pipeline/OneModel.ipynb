{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## For platforms\n",
        "import os\n",
        "\n",
        "\n",
        "def get_platform():\n",
        "    platform = ''\n",
        "\n",
        "    # Windows\n",
        "    if os.name == 'nt':\n",
        "        try:\n",
        "            get_ipython().__class__.__name__\n",
        "            platform = 'jupyter'\n",
        "        except NameError:\n",
        "            platform = 'python'\n",
        "\n",
        "    elif os.name == 'posix':\n",
        "        # Kaggle\n",
        "        if 'KAGGLE_DATA_PROXY_TOKEN' in os.environ.keys():\n",
        "            platform = 'kaggle'\n",
        "\n",
        "    # Google Colab\n",
        "        else:\n",
        "            try:\n",
        "                from google.colab import drive\n",
        "                platform = 'colab'\n",
        "            except ModuleNotFoundError:\n",
        "                platform = None\n",
        "\n",
        "    print(f'Use: {platform}')\n",
        "    return platform\n",
        "\n",
        "\n",
        "def colab_action():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    os.chdir(f'/content/drive/My Drive/LOB/Pipeline')\n",
        "    os.system('pip install automodinit keras_tuner')\n",
        "    os.system('nohup /usr/bin/python3 Colab_saver.py &')\n",
        "\n",
        "\n",
        "def kaggle_action():\n",
        "    ...\n",
        "\n",
        "\n",
        "platform = get_platform()\n",
        "if platform == 'colab':\n",
        "    colab_action()\n",
        "elif platform == 'kaggle':\n",
        "    kaggle_action()\n",
        "\n",
        "import backend as B\n",
        "\n",
        "B.set_backend(platform)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from backend import DataBack, ModelBack, DataClass\n",
        "\n",
        "seq_len = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models import m_base as test_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load data\n",
        "data_back = DataBack()\n",
        "proportion = input('Data proportion 100-0 in % (press enter for all): ')\n",
        "if proportion == '': proportion = 1\n",
        "else: proportion = float(proportion) / 100\n",
        "\n",
        "train, val, test = data_back.read_saved_data(\n",
        "    proportion=proportion,\n",
        "    train_indexes=[0],\n",
        "    val_indexes=[0],\n",
        ")\n",
        "print(data_back.last_data_info)\n",
        "data_back.inspect_data(train=train, val=val, test=test)\n",
        "\n",
        "ds_train = data_back.data_to_dataset(\n",
        "    data=train,\n",
        "    seq_len=seq_len,\n",
        "    batch_size=100,\n",
        ")\n",
        "ds_val = data_back.data_to_dataset(data=val, seq_len=seq_len, batch_size=100)\n",
        "data_back.inspect_dataset(train=ds_train, val=ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEFAULT_PARAMETRS = DataClass(test_model.PARAMETRS)\n",
        "print(DEFAULT_PARAMETRS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Build\n",
        "tf.keras.backend.clear_session()\n",
        "restore = True if input('Restore? (y-yes, enter-no): ') == 'y' else False\n",
        "input_name = ''\n",
        "while input_name == '':\n",
        "    input_name = input(\n",
        "        f\"Input train name to {'restore' if restore else 'build new'}: \")\n",
        "\n",
        "if restore:\n",
        "    model, train_name = ModelBack.restore_model(input_name)\n",
        "\n",
        "else:\n",
        "    ## Set up parametrs\n",
        "    PARAMETRS = DEFAULT_PARAMETRS.COPY()\n",
        "    model = test_model.blocks.build_model(**PARAMETRS.DATA)\n",
        "    train_name = ModelBack.get_training_name(input_name)\n",
        "    print(\n",
        "        f'Pattern model: {test_model.__name__}',\n",
        "        f'Train name: {train_name}',\n",
        "        'Parametrs:',\n",
        "        DEFAULT_PARAMETRS.COMPARE(PARAMETRS),\n",
        "        sep='\\n',\n",
        "    )\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Callbacks\n",
        "callback_freq = 1\n",
        "train_dir = f'{ModelBack.callback_path}/{train_name}'\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=train_dir,\n",
        "        histogram_freq=1,\n",
        "        update_freq=callback_freq,\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        f'{train_dir}/checkpoints/' + '{epoch:04d}.keras',\n",
        "        monitor=\"val_sp_acc\",\n",
        "        verbose=0,\n",
        "        save_best_only=False,\n",
        "        save_weights_only=False,\n",
        "        mode=\"auto\",\n",
        "        save_freq=callback_freq,\n",
        "    )\n",
        "]\n",
        "ModelBack.dump(\n",
        "    data_info=data_back.last_data_info,\n",
        "    parametrs=DEFAULT_PARAMETRS.COMPARE(PARAMETRS),\n",
        "    model_path=train_dir,\n",
        ")\n",
        "print(\n",
        "    f\"Callbacks:\\n{[str(type(callback)).split('.')[-1] for callback in callbacks]}\",\n",
        "    f'Directory: {train_dir}',\n",
        "    sep='\\n',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Train\n",
        "training_question = ''\n",
        "while training_question not in ['y', 'n']:\n",
        "    training_question = input(f'Start training now (y-yes) (n-exit): ')\n",
        "if training_question == 'y':\n",
        "    model.fit(\n",
        "        ds_train,\n",
        "        epochs=20,\n",
        "        validation_data=ds_val,\n",
        "        callbacks=callbacks,\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.10.0 ('zGPU_env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "15c3c8882de147eda8616aa412d6cb2a921cdd19c8088b1f5bdfa95af6065bbb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
