{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use: jupyter\n",
            "Using TensorFlow backend\n",
            "Dataset  : ../dataset/saved_data\n",
            "Callbacks: ../Temp/callbacks\n"
          ]
        }
      ],
      "source": [
        "## For platforms\n",
        "import os\n",
        "\n",
        "\n",
        "def get_platform():\n",
        "    platform = ''\n",
        "\n",
        "    # Windows\n",
        "    if os.name == 'nt':\n",
        "        try:\n",
        "            get_ipython().__class__.__name__\n",
        "            platform = 'jupyter'\n",
        "        except NameError:\n",
        "            platform = 'python'\n",
        "\n",
        "    elif os.name == 'posix':\n",
        "        # Kaggle\n",
        "        if 'KAGGLE_DATA_PROXY_TOKEN' in os.environ.keys():\n",
        "            platform = 'kaggle'\n",
        "\n",
        "    # Google Colab\n",
        "        else:\n",
        "            try:\n",
        "                from google.colab import drive\n",
        "                platform = 'colab'\n",
        "            except ModuleNotFoundError:\n",
        "                platform = None\n",
        "\n",
        "    print(f'Use: {platform}')\n",
        "    return platform\n",
        "\n",
        "\n",
        "def colab_action():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    os.chdir(f'/content/drive/My Drive/LOB/Pipeline')\n",
        "    os.system('pip install automodinit keras_tuner')\n",
        "    os.system('nohup /usr/bin/python3 Colab_saver.py &')\n",
        "\n",
        "\n",
        "def kaggle_action():\n",
        "    ...\n",
        "\n",
        "\n",
        "platform = get_platform()\n",
        "if platform == 'colab':\n",
        "    colab_action()\n",
        "elif platform == 'kaggle':\n",
        "    kaggle_action()\n",
        "\n",
        "\n",
        "import backend as B\n",
        "B.set_backend(platform)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from backend import DataBack,ModelBack,DataClass\n",
        "seq_len = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models import m_base as test_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read raw data, info writen to last_data_info.\n",
            "    Datas:\n",
            "train     : x= (15804, 40)     | y= (15804,)       \n",
            "val       : x= (3951, 40)      | y= (3951,)        \n",
            "    Datasets:\n",
            "train : [158, 100, 40]\n",
            "val   : [39, 100, 40]\n"
          ]
        }
      ],
      "source": [
        "## Load data\n",
        "data_back =DataBack()\n",
        "proportion = input('Data proportion 100-0 in % (press enter for all): ')\n",
        "if proportion == '': proportion = 1\n",
        "else: proportion = float(proportion) / 100\n",
        "\n",
        "train, val, test = data_back.read_saved_data(proportion=proportion,\n",
        "                                       train_indexes=[0],\n",
        "                                       val_indexes=[0])\n",
        "data_back.inspect_data(train=train, val=val, test=test)\n",
        "\n",
        "ds_train = data_back.data_to_dataset(data=train, seq_len=seq_len, batch_size=100)\n",
        "ds_val = data_back.data_to_dataset(data=val, seq_len=seq_len, batch_size=100)\n",
        "data_back.inspect_dataset(train=ds_train, val=ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'read_from': 'saved',\n",
              " 'proportion': 0.5,\n",
              " 'train_indexes': [0],\n",
              " 'val_indexes': [0],\n",
              " 'test_indexes': []}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_back.last_data_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "convolutional\n",
              "├─ dilation_steps: 4\n",
              "└─ filters: 14\n",
              "feed_forward\n",
              "├─ activation: function relu\n",
              "├─ dropout_rate: 0.1\n",
              "├─ kernel_initializer: glorot_uniform\n",
              "├─ kernel_regularizer: keras.regularizers.L2 object\n",
              "├─ out_activation: softmax\n",
              "└─ units: 64\n",
              "optimizer: keras.optimizers.legacy.adam.Adam object\n",
              "seq_len: 100\n",
              "transformer\n",
              "├─ blocks: 2\n",
              "├─ heads: 3\n",
              "└─ share_weights: False"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PARAMETRS= DataClass(test_model.PARAMETRS)\n",
        "PARAMETRS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Build\n",
        "tf.keras.backend.clear_session()\n",
        "restore = True if input('Restore? (y-yes, enter-no): ') == 'y' else False\n",
        "input_name = ''\n",
        "while input_name == '':\n",
        "    input_name = input(\n",
        "        f\"Input train name to {'restore' if restore else 'build new'}: \")\n",
        "if restore:\n",
        "    model, train_name = ModelBack.restore_model(input_name)\n",
        "else:\n",
        "    ## Set up parametrs\n",
        "    model = test_model.blocks.build_model(**PARAMETRS.DATA_NESTED)\n",
        "    train_name = ModelBack.get_training_name(input_name)\n",
        "    print(\n",
        "        f'Pattern model: {test_model.__name__}',\n",
        "        f'Train name: {train_name}',\n",
        "        'Parametrs:',\n",
        "        PARAMETRS,\n",
        "        sep='\\n',\n",
        "    )\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Callbacks\n",
        "callback_freq = 1\n",
        "train_dir = f'{ModelBack.callback_path}/{train_name}'\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=train_dir,\n",
        "        histogram_freq=1,\n",
        "        update_freq=callback_freq,\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        f'{train_dir}/checkpoints/' + '{epoch:04d}.keras',\n",
        "        monitor=\"val_sp_acc\",\n",
        "        verbose=0,\n",
        "        save_best_only=False,\n",
        "        save_weights_only=False,\n",
        "        mode=\"auto\",\n",
        "        save_freq=callback_freq,\n",
        "    )\n",
        "]\n",
        "ModelBack.dump_data(data=PARAMETRS,model_path=train_dir)\n",
        "print(\n",
        "    f\"Callbacks:\\n{[str(type(callback)).split('.')[-1] for callback in callbacks]}\",\n",
        "    f'Directory: {train_dir}',\n",
        "    sep='\\n',\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Train\n",
        "training_question = ''\n",
        "while training_question not in ['y', 'n']:\n",
        "    training_question = input(f'Start training now (y-yes) (n-exit): ')\n",
        "if training_question == 'y':\n",
        "    model.fit(\n",
        "        ds_train,\n",
        "        epochs=20,\n",
        "        validation_data=ds_val,\n",
        "        callbacks=callbacks,\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.10.0 ('zGPU_env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "15c3c8882de147eda8616aa412d6cb2a921cdd19c8088b1f5bdfa95af6065bbb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
