{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For platforms\n",
    "import os\n",
    "\n",
    "\n",
    "def get_platform():\n",
    "    platform = ''\n",
    "\n",
    "    # Windows\n",
    "    if os.name == 'nt':\n",
    "        try:\n",
    "            get_ipython().__class__.__name__\n",
    "            platform = 'jupyter'\n",
    "        except NameError:\n",
    "            platform = 'python'\n",
    "\n",
    "    elif os.name == 'posix':\n",
    "        # Kaggle\n",
    "        if 'KAGGLE_DATA_PROXY_TOKEN' in os.environ.keys():\n",
    "            platform = 'kaggle'\n",
    "\n",
    "    # Google Colab\n",
    "        else:\n",
    "            try:\n",
    "                from google.colab import drive\n",
    "                platform = 'colab'\n",
    "            except ModuleNotFoundError:\n",
    "                platform = None\n",
    "\n",
    "    print(f'Use: {platform}')\n",
    "    return platform\n",
    "\n",
    "\n",
    "def colab_action():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/', force_remount=True)\n",
    "    os.chdir(f'/content/drive/My Drive/LOB/Pipeline')\n",
    "    os.system('pip install automodinit keras_tuner')\n",
    "    os.system('nohup /usr/bin/python3 Colab_saver.py &')\n",
    "\n",
    "\n",
    "def kaggle_action():\n",
    "    ...\n",
    "\n",
    "\n",
    "platform = get_platform()\n",
    "if platform == 'colab':\n",
    "    colab_action()\n",
    "elif platform == 'kaggle':\n",
    "    kaggle_action()\n",
    "\n",
    "import backend as B\n",
    "\n",
    "B.set_backend(platform)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "\n",
    "from backend import DataBack, ModelBack, DataClass\n",
    "\n",
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import m_base as test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Savig data\n",
    "# header = '../dataset/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore'\n",
    "# train_files= [\n",
    "#         f'{header}_Training/Train_Dst_NoAuction_ZScore_CF_{i}.txt'\n",
    "#         for i in range(7, 8)\n",
    "#     ]\n",
    "\n",
    "# test_files=[\n",
    "#         f'{header}_Testing/Test_Dst_NoAuction_ZScore_CF_{i}.txt'\n",
    "#         for i in range(1, 2)\n",
    "#     ]\n",
    "\n",
    "# all,test = Datasets.from_files(train_files)\n",
    "# train, val = Datasets.validation_split(all)\n",
    "# Datasets.inspect_data(train=train,val=val)\n",
    "# Datasets.save_data(train=train,val=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "proportion = input('Data proportion 100-0 in % (press enter for all): ')\n",
    "if proportion == '': proportion = 1\n",
    "else: proportion = float(proportion) / 100\n",
    "\n",
    "train, val, test = DataBack.from_saved(proportion=proportion,\n",
    "                                       train_indexes=[0],\n",
    "                                       val_indexes=[0])\n",
    "DataBack.inspect_data(train=train, val=val, test=test)\n",
    "\n",
    "ds_train = DataBack.build_dataset(data=train, seq_len=seq_len, batch_size=100)\n",
    "ds_val = DataBack.build_dataset(data=val, seq_len=seq_len, batch_size=100)\n",
    "DataBack.inspect_dataset(train=ds_train, val=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETRS = DataClass(test_model.PARAMETRS)\n",
    "PARAMETRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuner parametrs\n",
    "# def configure(hp: keras_tuner.HyperParameters):\n",
    "\n",
    "#     class CN_search(DataClass):\n",
    "#         dilation_steps = hp.Int(\n",
    "#             'dilation_steps',\n",
    "#             default=4,\n",
    "#             min_value=3,\n",
    "#             max_value=5,\n",
    "#             step=1,\n",
    "#         )\n",
    "\n",
    "#     class AN_search(DataClass):\n",
    "#         share_weights = hp.Boolean(\n",
    "#             'share_weights',\n",
    "#             default=True,\n",
    "#         )\n",
    "#         blocks = hp.Int(\n",
    "#             'an_blocks',\n",
    "#             default=2,\n",
    "#             min_value=1,\n",
    "#             max_value=3,\n",
    "#             step=1,\n",
    "#         )\n",
    "\n",
    "#     class Full_search(DataClass):\n",
    "#         cn = CN_search()\n",
    "#         an = AN_search()\n",
    "\n",
    "#     return Full_search()\n",
    "\n",
    "\n",
    "def configure_parametrs(hp: keras_tuner.HyperParameters):\n",
    "\n",
    "    PARAMETRS.convolutional.dilation_steps = 5\n",
    "\n",
    "    PARAMETRS.transformer.share_weights = False\n",
    "\n",
    "    choices = {'l2': 'l2', 'None': None}\n",
    "    choice = hp.Choice(\n",
    "        name='regularizer',\n",
    "        values=list(choices),\n",
    "        default='None',\n",
    "    )\n",
    "    PARAMETRS.feed_forward.kernel_regularizer = choices[choice]\n",
    "\n",
    "    lr = hp.Choice(\n",
    "        name='lr',\n",
    "        default=0.0001,\n",
    "        values=[0.01, 0.001, 0.0005, 0.0001],\n",
    "    )\n",
    "    choices = {\n",
    "        'sgd':\n",
    "        tf.keras.optimizers.legacy.SGD(learning_rate=lr),\n",
    "        'rms':\n",
    "        tf.keras.optimizers.legacy.RMSprop(learning_rate=lr),\n",
    "        'adam':\n",
    "        tf.keras.optimizers.legacy.Adam(\n",
    "            learning_rate=lr,\n",
    "            beta_1=0.9,\n",
    "            beta_2=0.999,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    choice = hp.Choice(\n",
    "        name='optimazer',\n",
    "        default='adam',\n",
    "        values=['adam', 'rms', 'sgd'],\n",
    "    )\n",
    "    PARAMETRS.optimizer = choices[choice]\n",
    "    return PARAMETRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build\n",
    "def search_model(hp):\n",
    "    parametrs = configure_parametrs(hp)\n",
    "    model = test_model.blocks.build_model(**parametrs.DATA_NESTED)\n",
    "    return model\n",
    "\n",
    "\n",
    "input_name = ''\n",
    "while input_name == '':\n",
    "    input_name = input(f\"Input search name: \")\n",
    "search_name = ModelBack.get_search_name(input_name)\n",
    "\n",
    "print(\n",
    "    f'Pattern model: {test_model.__name__}',\n",
    "    f'Search name: {search_name}',\n",
    "    'Parametrs:',\n",
    "    configure_parametrs(keras_tuner.HyperParameters()),\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Callbacks\n",
    "callback_freq = 100\n",
    "search_dir = f\"{ModelBack.callback_path}/{search_name}\"\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=search_dir,\n",
    "        histogram_freq=callback_freq,\n",
    "        update_freq=callback_freq,\n",
    "    ),\n",
    "]\n",
    "ModelBack.dump_data(data=PARAMETRS, model_path=search_dir)\n",
    "print(\n",
    "    f\"Callbacks:\\n{[str(type(callback)).split('.')[-1] for callback in callbacks]}\",\n",
    "    f'Directory: {search_dir}',\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build tuner\n",
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=search_model,\n",
    "    objective=\"loss\",\n",
    "    executions_per_trial=1,\n",
    "    directory=search_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train\n",
    "training_question = ''\n",
    "while training_question not in ['y', 'n']:\n",
    "    training_question = input('Start training now? (y-yes) (n-exit): ')\n",
    "if training_question == 'y':\n",
    "    tuner.search(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=20,\n",
    "        callbacks=callbacks,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zGPU_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15c3c8882de147eda8616aa412d6cb2a921cdd19c8088b1f5bdfa95af6065bbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
