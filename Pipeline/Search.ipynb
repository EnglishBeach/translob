{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: jupyter\n",
      "Dataset  : ../dataset/saved_data\n",
      "Callbacks: ../Temp/callbacks\n",
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "## For platforms\n",
    "import os\n",
    "\n",
    "\n",
    "def get_platform():\n",
    "    platform = ''\n",
    "\n",
    "    # Windows\n",
    "    if os.name == 'nt':\n",
    "        try:\n",
    "            get_ipython().__class__.__name__\n",
    "            platform = 'jupyter'\n",
    "        except NameError:\n",
    "            platform = 'python'\n",
    "\n",
    "    elif os.name == 'posix':\n",
    "        # Kaggle\n",
    "        if 'KAGGLE_DATA_PROXY_TOKEN' in os.environ.keys():\n",
    "            platform = 'kaggle'\n",
    "\n",
    "    # Google Colab\n",
    "        else:\n",
    "            try:\n",
    "                from google.colab import drive\n",
    "                platform = 'colab'\n",
    "            except ModuleNotFoundError:\n",
    "                platform = None\n",
    "\n",
    "    print(f'Use: {platform}')\n",
    "    return platform\n",
    "\n",
    "\n",
    "def colab_action():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/', force_remount=True)\n",
    "    os.chdir(f'/content/drive/My Drive/LOB/Pipeline')\n",
    "    os.system('pip install automodinit keras_tuner')\n",
    "    os.system('nohup /usr/bin/python3 Colab_saver.py &')\n",
    "\n",
    "\n",
    "def kaggle_action():\n",
    "    ...\n",
    "\n",
    "\n",
    "platform = get_platform()\n",
    "if platform == 'colab':\n",
    "    colab_action()\n",
    "elif platform == 'kaggle':\n",
    "    kaggle_action()\n",
    "\n",
    "import backend as B\n",
    "\n",
    "B.set_backend(platform)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "\n",
    "from backend import DataBack, ModelBack, DataClass\n",
    "\n",
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import m_preln as test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Savig data\n",
    "# header = '../dataset/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore'\n",
    "# train_files= [\n",
    "#         f'{header}_Training/Train_Dst_NoAuction_ZScore_CF_{i}.txt'\n",
    "#         for i in range(7, 8)\n",
    "#     ]\n",
    "\n",
    "# test_files=[\n",
    "#         f'{header}_Testing/Test_Dst_NoAuction_ZScore_CF_{i}.txt'\n",
    "#         for i in range(1, 2)\n",
    "#     ]\n",
    "\n",
    "# all,test = Datasets.from_files(train_files)\n",
    "# train, val = Datasets.validation_split(all)\n",
    "# Datasets.inspect_data(train=train,val=val)\n",
    "# Datasets.save_data(train=train,val=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Datas:\n",
      "train     : x= (40759, 40)     | y= (40759,)       \n",
      "val       : x= (10190, 40)     | y= (10190,)       \n",
      "    Datasets:\n",
      "train : [407, 100, 40]\n",
      "val   : [101, 100, 40]\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "proportion = input('Data proportion 100-0 in % (press enter for all): ')\n",
    "if proportion == '': proportion = 1\n",
    "else: proportion = float(proportion) / 100\n",
    "\n",
    "train, val, test = DataBack.from_saved(proportion=proportion,\n",
    "                                       train_indexes=[0],\n",
    "                                       val_indexes=[0])\n",
    "DataBack.inspect_data(train=train, val=val, test=test)\n",
    "\n",
    "ds_train = DataBack.build_dataset(data=train, seq_len=seq_len, batch_size=100)\n",
    "ds_val = DataBack.build_dataset(data=val, seq_len=seq_len, batch_size=100)\n",
    "DataBack.inspect_dataset(train=ds_train, val=ds_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convolutional\n",
       "├─ dilation_steps: 4\n",
       "└─ filters: 14\n",
       "feed_forward\n",
       "├─ activation: function relu\n",
       "├─ dropout_rate: 0.1\n",
       "├─ kernel_initializer: glorot_uniform\n",
       "├─ kernel_regularizer: keras.regularizers.L2 object\n",
       "├─ out_activation: softmax\n",
       "└─ units: 64\n",
       "optimizer: keras.optimizers.legacy.adam.Adam object\n",
       "seq_len: 100\n",
       "transformer\n",
       "├─ blocks: 2\n",
       "├─ heads: 3\n",
       "└─ share_weights: False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAMETRS = DataClass(test_model.PARAMETRS)\n",
    "PARAMETRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuner parametrs\n",
    "def configure_parametrs(hp: keras_tuner.HyperParameters):\n",
    "    parametrs= DataClass(PARAMETRS.DATA_NESTED)\n",
    "    parametrs.convolutional.dilation_steps = hp.Int(\n",
    "            'dilation_steps',\n",
    "            default=4,\n",
    "            min_value=3,\n",
    "            max_value=5,\n",
    "            step=1,\n",
    "        )\n",
    "\n",
    "    parametrs.transformer.share_weights = hp.Boolean(\n",
    "            'share_weights',\n",
    "            default=True,\n",
    "        )\n",
    "    \n",
    "    parametrs.transformer.blocks = hp.Int(\n",
    "            'an_blocks',\n",
    "            default=2,\n",
    "            min_value=1,\n",
    "            max_value=3,\n",
    "            step=1,\n",
    "        )\n",
    "    return parametrs\n",
    "\n",
    "\n",
    "# def configure_parametrs(hp: keras_tuner.HyperParameters):\n",
    "\n",
    "#     parametrs.convolutional.dilation_steps = 5\n",
    "\n",
    "#     parametrs.transformer.share_weights = False\n",
    "\n",
    "#     choices = {'l2': 'l2', 'None': None}\n",
    "#     choice = hp.Choice(\n",
    "#         name='regularizer',\n",
    "#         values=list(choices),\n",
    "#         default='None',\n",
    "#     )\n",
    "#     parametrs.feed_forward.kernel_regularizer = choices[choice]\n",
    "\n",
    "#     lr = hp.Choice(\n",
    "#         name='lr',\n",
    "#         default=0.0001,\n",
    "#         values=[0.01, 0.001, 0.0005, 0.0001],\n",
    "#     )\n",
    "#     choices = {\n",
    "#         'sgd':\n",
    "#         tf.keras.optimizers.legacy.SGD(learning_rate=lr),\n",
    "#         'rms':\n",
    "#         tf.keras.optimizers.legacy.RMSprop(learning_rate=lr),\n",
    "#         'adam':\n",
    "#         tf.keras.optimizers.legacy.Adam(\n",
    "#             learning_rate=lr,\n",
    "#             beta_1=0.9,\n",
    "#             beta_2=0.999,\n",
    "#         ),\n",
    "#     }\n",
    "\n",
    "#     choice = hp.Choice(\n",
    "#         name='optimazer',\n",
    "#         default='adam',\n",
    "#         values=['adam', 'rms', 'sgd'],\n",
    "#     )\n",
    "#     parametrs.optimizer = choices[choice]\n",
    "#     return parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern model: models.m_preln\n",
      "Search name: search_test(13;18;13--15.10)\n",
      "Parametrs:\n",
      "convolutional\n",
      "├─ dilation_steps: 4\n",
      "└─ filters: 14\n",
      "feed_forward\n",
      "├─ activation: function relu\n",
      "├─ dropout_rate: 0.1\n",
      "├─ kernel_initializer: glorot_uniform\n",
      "├─ kernel_regularizer: keras.regularizers.L2 object\n",
      "├─ out_activation: softmax\n",
      "└─ units: 64\n",
      "optimizer: keras.optimizers.legacy.adam.Adam object\n",
      "seq_len: 100\n",
      "transformer\n",
      "├─ blocks: 2\n",
      "├─ heads: 3\n",
      "└─ share_weights: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Build\n",
    "def search_model(hp):\n",
    "    parametrs = configure_parametrs(hp)\n",
    "    model = test_model.blocks.build_model(**parametrs.DATA_NESTED)\n",
    "    return model\n",
    "\n",
    "\n",
    "input_name = ''\n",
    "while input_name == '':\n",
    "    input_name = input(f\"Input search name: \")\n",
    "search_name = ModelBack.get_search_name(input_name)\n",
    "\n",
    "print(\n",
    "    f'Pattern model: {test_model.__name__}',\n",
    "    f'Search name: {search_name}',\n",
    "    'Parametrs:',\n",
    "    configure_parametrs(keras_tuner.HyperParameters()),\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=DataClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.g=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convolutional\n",
       "├─ dilation_steps: 4\n",
       "└─ filters: 14\n",
       "feed_forward\n",
       "├─ activation: function relu\n",
       "├─ dropout_rate: 0.1\n",
       "├─ kernel_initializer: glorot_uniform\n",
       "├─ kernel_regularizer: keras.regularizers.L2 object\n",
       "├─ out_activation: softmax\n",
       "└─ units: 64\n",
       "optimizer: keras.optimizers.legacy.adam.Adam object\n",
       "seq_len: 100\n",
       "transformer\n",
       "├─ blocks: 2\n",
       "├─ heads: 3\n",
       "└─ share_weights: True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configure_parametrs(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Callbacks\n",
    "callback_freq = 100\n",
    "search_dir = f\"{ModelBack.callback_path}/{search_name}\"\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=search_dir,\n",
    "        histogram_freq=callback_freq,\n",
    "        update_freq=callback_freq,\n",
    "    ),\n",
    "]\n",
    "\n",
    "dump_description = input(f\"Input description: \")\n",
    "dump_parametrs = PARAMETRS\n",
    "ModelBack.dump_data(data={'desc':dump_description,'parametrs':}, model_path=search_dir)\n",
    "print(\n",
    "    f\"Callbacks:\\n{[str(type(callback)).split('.')[-1] for callback in callbacks]}\",\n",
    "    f'Directory: {search_dir}',\n",
    "    sep='\\n',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build tuner\n",
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=search_model,\n",
    "    objective=\"loss\",\n",
    "    executions_per_trial=1,\n",
    "    directory=search_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train\n",
    "training_question = ''\n",
    "while training_question not in ['y', 'n']:\n",
    "    training_question = input('Start training now? (y-yes) (n-exit): ')\n",
    "if training_question == 'y':\n",
    "    tuner.search(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=20,\n",
    "        callbacks=callbacks,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('zGPU_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15c3c8882de147eda8616aa412d6cb2a921cdd19c8088b1f5bdfa95af6065bbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
